{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import s3fs\n",
    "import sunpy.map\n",
    "\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import sunpy.visualization.colormaps as cm\n",
    "\n",
    "from astropy.time import Time\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from sunpy.visualization import axis_labels_from_ctype, wcsaxes_compat\n",
    "\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def get_sdo_solar_images_from_aws(wanted_times, sav_folder_path):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return fetched_images_path\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this problem is still a work in progress\n",
    "# DASK is not freeing up memory after the computation is done\n",
    "# will need to address this issue in the future\n",
    "# fix dask cache size\n",
    "\n",
    "from dask.cache import Cache\n",
    "cache = Cache(1e9)  # Leverage 1 GB of memory\n",
    "cache.register()    # Turn cache on globally\n",
    "\n",
    "# AWS path to the solar images data (for 2015) on AWS S3\n",
    "AWS_ZARR_ROOT = (\n",
    "    \"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2.zarr/2015/\"\n",
    ")\n",
    "\n",
    "# Function to connect to AWS S3 to access the zarr data in S3\n",
    "def s3_connection(path_to_zarr: os.path) -> s3fs.S3Map:\n",
    "    \"\"\"\n",
    "    Instantiate connection to aws for a given path `path_to_zarr`\n",
    "    \"\"\"\n",
    "    return s3fs.S3Map(\n",
    "        root=path_to_zarr,\n",
    "        s3=s3fs.S3FileSystem(anon=True),\n",
    "        # anonymous access requires no credentials\n",
    "        check=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_single_aws_zarr(\n",
    "    path_to_zarr: os.path,\n",
    "    cache_max_single_size: int = None,\n",
    ") -> Union[zarr.Array, zarr.Group]:\n",
    "    \"\"\"\n",
    "    load zarr from s3 using LRU cache\n",
    "    \"\"\"\n",
    "    return zarr.open(\n",
    "        zarr.LRUStoreCache(\n",
    "            store=s3_connection(path_to_zarr),\n",
    "            max_size=cache_max_single_size,\n",
    "        ),\n",
    "        mode=\"r\",\n",
    "    )\n",
    "\n",
    "# first, we create a group with the store data located on GCP.\n",
    "root = load_single_aws_zarr(\n",
    "    path_to_zarr=AWS_ZARR_ROOT,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
