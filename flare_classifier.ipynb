{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TMntV5kj88Ll"
      },
      "outputs": [],
      "source": [
        "# to-do:\n",
        "# -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xZ5d83BIX0Jl",
        "outputId": "8f7db1ff-bbd3-499a-e28d-10b8323d8fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (2024.12.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: s3fs in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (2025.3.2)\n",
            "Requirement already satisfied: sunpy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (6.1.1)\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6)) (3.0.7)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (8.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /usr/local/lib/python3.11/dist-packages (from s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (2.22.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (3.11.15)\n",
            "Requirement already satisfied: astropy>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (7.0.1)\n",
            "Requirement already satisfied: parfive>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from parfive[ftp]>=2.0.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.11/dist-packages (from sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (2.0.1.5)\n",
            "Requirement already satisfied: requests>=2.28.0 in /usr/local/lib/python3.11/dist-packages (from sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.11/dist-packages (from zarr->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6)) (0.8.1.post1)\n",
            "Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.11/dist-packages (from numcodecs[crc32c]>=0.14->zarr->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9 in /usr/local/lib/python3.11/dist-packages (from zarr->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6)) (4.13.2)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: botocore<1.37.4,>=1.37.2 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.37.3)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (6.4.3)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.20.0)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.1.31.12.41.4 in /usr/local/lib/python3.11/dist-packages (from astropy>=6.0.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (0.2025.4.28.0.37.27)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (3.21.0)\n",
            "Requirement already satisfied: crc32c>=2.7 in /usr/local/lib/python3.11/dist-packages (from numcodecs[crc32c]>=0.14->zarr->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6)) (2.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from parfive>=2.0.0->parfive[ftp]>=2.0.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: aioftp>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from parfive[ftp]>=2.0.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (0.25.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# set globals\n",
        "\n",
        "# do Google Colab things\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# install dependencies\n",
        "path_to_coderepo = (\n",
        "    \"/content/drive/MyDrive/ML_project/code_repo/flare-finder\" if IN_COLAB else \".\"\n",
        ")\n",
        "if IN_COLAB:\n",
        "    !pip install -r {path_to_coderepo}/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DNmcTVnQ0MXA"
      },
      "outputs": [],
      "source": [
        "# creating model class for big flare prediction\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import ResNet18_Weights\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class BigFlareFinder:\n",
        "    def __init__(self):\n",
        "\n",
        "        # init pytorch model\n",
        "        self.pytorch_model = None\n",
        "\n",
        "        # set things to make training deterministic\n",
        "        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "        torch.manual_seed(42)\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "\n",
        "        # set device\n",
        "        self.device = None\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "\n",
        "    def fit(self, image_paths, image_labels, val_frac=0.5):\n",
        "\n",
        "        # split the data into train and validation using time\n",
        "        image_paths_train, image_paths_val, image_labels_train, image_labels_val = (\n",
        "            BigFlareFinder.split_into_train_test_by_time(image_paths, image_labels, val_frac)\n",
        "        )\n",
        "\n",
        "        # for training, augment minority-class by making copies\n",
        "        image_paths_train, image_labels_train = BigFlareFinder.augment_minority_class(\n",
        "            image_paths_train, image_labels_train\n",
        "        )\n",
        "\n",
        "        # get dataloader for train and validation data\n",
        "        train_loader = BigFlareFinder.preprocess(image_paths_train, image_labels_train)\n",
        "        validation_loader = BigFlareFinder.preprocess(image_paths_val, image_labels_val)\n",
        "\n",
        "        # fit pytorch model using dataloader\n",
        "\n",
        "        # load resnet18 model\n",
        "        # model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
        "        model_resnet18 = torch.hub.load(\n",
        "            \"pytorch/vision\", \"resnet18\", weights=ResNet18_Weights.DEFAULT\n",
        "        )\n",
        "\n",
        "        # Freeze all params except the BatchNorm layers, as here they are trained to the\n",
        "        # mean and standard deviation of ImageNet and we may lose some signal\n",
        "        for name, param in model_resnet18.named_parameters():\n",
        "            if \"bn\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # reduce number of output classes in model\n",
        "        num_classes = 2\n",
        "        model_resnet18.fc = nn.Sequential(\n",
        "            nn.Linear(model_resnet18.fc.in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "        model_resnet18.to(self.device)\n",
        "        optimizer = optim.Adam(model_resnet18.parameters())\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        epochs = 7  # 10\n",
        "        target_class = 1\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            training_loss = 0.0\n",
        "            valid_loss = 0.0\n",
        "            model_resnet18.train()\n",
        "            for batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                inputs, targets = batch\n",
        "                targets = targets.type(torch.LongTensor)\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                output = model_resnet18(inputs)\n",
        "                loss = loss_fn(output, targets)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                training_loss += loss.data.item() * inputs.size(0)\n",
        "            training_loss /= len(train_loader.dataset)\n",
        "\n",
        "            model_resnet18.eval()\n",
        "            # all_targets = []\n",
        "            image_labels_val_pred = []\n",
        "\n",
        "            for batch in validation_loader:\n",
        "                inputs, targets = batch\n",
        "                inputs = inputs.to(self.device)\n",
        "                output = model_resnet18(inputs)\n",
        "                predictions = torch.max(F.softmax(output, dim=1), dim=1)[1]\n",
        "                image_labels_val_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "            print(\n",
        "                f\"Train epoch: {epoch}\"\n",
        "                f\", train_loss: {round(training_loss, 2)}\"\n",
        "                f\"\\nval_metrics: {BigFlareFinder.get_model_performance_metrics(image_labels_val, image_labels_val_pred)}\"\n",
        "            )\n",
        "\n",
        "        # train on the val data (which was excluded from training earlier)\n",
        "        image_paths_val, image_labels_val = BigFlareFinder.augment_minority_class(\n",
        "            image_paths_val, image_labels_val\n",
        "        )\n",
        "        val_loader = BigFlareFinder.preprocess(image_paths_val, image_labels_val)\n",
        "        for epoch in range(epochs):\n",
        "            for batch in val_loader:\n",
        "                optimizer.zero_grad()\n",
        "                inputs, targets = batch\n",
        "                targets = targets.type(torch.LongTensor)\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                output = model_resnet18(inputs)\n",
        "                loss = loss_fn(output, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                training_loss += loss.data.item() * inputs.size(0)\n",
        "            training_loss /= len(train_loader.dataset)\n",
        "            model_resnet18.eval()\n",
        "            print(\n",
        "                f\"Train-on-val epoch: {epoch}\"\n",
        "                f\", train_loss: {round(training_loss, 2)}\"\n",
        "            )\n",
        "\n",
        "        # save trained model to self\n",
        "        self.pytorch_model = model_resnet18\n",
        "\n",
        "    @staticmethod\n",
        "    def augment_minority_class(image_paths, image_labels):\n",
        "        # TODO: remove funtion after implementing augmentation in preprocess\n",
        "\n",
        "        # init resut\n",
        "        image_paths_aug = []\n",
        "        image_labels_aug = []\n",
        "\n",
        "        # augment data\n",
        "        image_labels_counts = pd.Series(image_labels).value_counts().sort_values()\n",
        "        minority_class, majority_class = tuple(image_labels_counts.index)\n",
        "        class_count_diff = (\n",
        "            image_labels_counts[majority_class] - image_labels_counts[minority_class]\n",
        "        )\n",
        "        image_paths_new = (\n",
        "            pd.Series(image_paths[image_labels == minority_class])\n",
        "            .sample(class_count_diff, replace=True, random_state=42)\n",
        "            .to_list()\n",
        "        )\n",
        "        image_labels_new = [minority_class] * class_count_diff\n",
        "        image_paths_aug = image_paths + image_paths_new\n",
        "        image_labels_aug = image_labels + image_labels_new\n",
        "\n",
        "        # shuffle augmented data\n",
        "        image_paths_aug, image_labels_aug = zip(\n",
        "            *np.random.default_rng(seed=42).permutation(\n",
        "                list(zip(image_paths_aug, image_labels_aug))\n",
        "            )\n",
        "        )\n",
        "        image_paths_aug = [str(path) for path in image_paths_aug]\n",
        "        image_labels_aug = [float(label) for label in image_labels_aug]\n",
        "\n",
        "        return image_paths_aug, image_labels_aug\n",
        "\n",
        "    def predict(self, image_paths):\n",
        "\n",
        "        # init result\n",
        "        pred_labels = []\n",
        "\n",
        "        # get dataloader\n",
        "        dataloader = BigFlareFinder.preprocess(image_paths)\n",
        "\n",
        "        # make predictions\n",
        "        for batch in dataloader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(self.device)\n",
        "            output = self.pytorch_model(inputs)\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)[1]\n",
        "            pred_labels.extend(predictions.cpu().numpy())\n",
        "\n",
        "        return pred_labels\n",
        "\n",
        "    def pred_proba(self, image_paths):\n",
        "\n",
        "        # init result\n",
        "        pred_probas = []\n",
        "\n",
        "        # get dataloader\n",
        "        dataloader = BigFlareFinder.preprocess(image_paths)\n",
        "\n",
        "        # make predictions\n",
        "        for batch in dataloader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(self.device)\n",
        "            output = self.pytorch_model(inputs)\n",
        "            predictions = F.softmax(output, dim=1)[:, 1]\n",
        "            pred_probas.extend(float(predictions.detach().cpu().numpy()))\n",
        "\n",
        "        return pred_probas\n",
        "\n",
        "    @staticmethod\n",
        "    def get_model_performance_metrics(y_true, y_pred):\n",
        "        metrics_dict = {\n",
        "            \"accuracy\": round(accuracy_score(y_true, y_pred), 2),\n",
        "            \"f1\": round(f1_score(y_true, y_pred), 2),\n",
        "            \"precision_class_1\": round(\n",
        "                precision_score(y_true, y_pred, zero_division=0), 2\n",
        "            ),\n",
        "            \"recall_class_1\": round(recall_score(y_true, y_pred, zero_division=0), 2),\n",
        "            \"actual_distru\": pd.Series(y_true).value_counts().sort_index().to_dict(),\n",
        "            \"pred_distru\": pd.Series(y_pred).value_counts().sort_index().to_dict(),\n",
        "        }\n",
        "        return metrics_dict\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(image_paths, image_labels=None, augment_minority_class=False):\n",
        "        # TODO: add data augmentation option; see https://stackoverflow.com/questions/51677788/data-augmentation-in-pytorch\n",
        "\n",
        "        # make dataset of image_paths and image_labels\n",
        "        image_dimension = 224\n",
        "        image_transforms = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((image_dimension, image_dimension)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        image_labels = image_labels or [0] * len(image_paths)\n",
        "        dataset = CustomImageDataset(image_paths, image_labels, image_transforms)\n",
        "\n",
        "        # make dataloader for dataset\n",
        "        batch_size = 32\n",
        "        num_workers = 2\n",
        "        dataloader = DataLoader(\n",
        "            dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
        "        )\n",
        "\n",
        "        return dataloader\n",
        "\n",
        "    @staticmethod\n",
        "    def split_into_train_test_by_time(image_paths, image_labels, test_frac):\n",
        "        # make images_df\n",
        "        images_df = pd.DataFrame(\n",
        "            {\"image_path\": image_paths, \"image_label\": image_labels}\n",
        "        )\n",
        "\n",
        "        # add a datetime column\n",
        "        images_df[\"datetime\"] = pd.to_datetime(\n",
        "            images_df[\"image_path\"].str.split(\"/\").str[-1].str[None:-4]\n",
        "        )\n",
        "\n",
        "        # sort images_df by datetime\n",
        "        images_df = images_df.sort_values(\"datetime\")\n",
        "\n",
        "        # find min and max datetimes of images_df\n",
        "        min_datetime = images_df[\"datetime\"].min()\n",
        "        max_datetime = images_df[\"datetime\"].max()\n",
        "\n",
        "        # find time span between min and max datetimes (in days)\n",
        "        time_span_in_days = (max_datetime - min_datetime).days\n",
        "\n",
        "        # get the two dfs by splitting the time span into the desired ratio\n",
        "        num_train_days = time_span_in_days * (1 - test_frac)\n",
        "        end_train_datetime = min_datetime + pd.to_timedelta(num_train_days, unit=\"days\")\n",
        "        train_df = images_df[images_df[\"datetime\"] <= end_train_datetime]\n",
        "        test_df = images_df[images_df[\"datetime\"] > end_train_datetime]\n",
        "\n",
        "        # get image_paths_train, image_paths_test, image_labels_train, image_labels_test\n",
        "        image_paths_train = train_df[\"image_path\"].to_list()\n",
        "        image_paths_test = test_df[\"image_path\"].to_list()\n",
        "        image_labels_train = train_df[\"image_label\"].to_list()\n",
        "        image_labels_test = test_df[\"image_label\"].to_list()\n",
        "\n",
        "        return (\n",
        "            image_paths_train,\n",
        "            image_paths_test,\n",
        "            image_labels_train,\n",
        "            image_labels_test,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to test the pred_proba functionality\n",
        "# * we want to train the model and use it get prediction probabilites given an image as input\n",
        "\n",
        "# get the image data: image_paths, image_labels\n",
        "image_folder_path = f\"{path_to_coderepo}/../../data/sdo_images_w=131a\"\n",
        "big_flare_labels_df = pd.read_csv(f\"{image_folder_path}/big_flare_labels.csv\").dropna()\n",
        "\n",
        "# [TEMP] shorten big_flare_labels_df\n",
        "big_flare_labels_df = big_flare_labels_df.sort_values('solar_image_filename').iloc[None:500]\n",
        "\n",
        "image_paths = (\n",
        "    image_folder_path + \"/\" + big_flare_labels_df[\"solar_image_filename\"]\n",
        ").to_list()\n",
        "image_labels = big_flare_labels_df[\"is_big_flare\"].to_list()\n",
        "\n",
        "# split image_paths and image_labels by time:\n",
        "#     image_paths_train, image_paths_test, image_labels_train, image_labels_test\n",
        "test_frac = 0.5\n",
        "image_paths_train, image_paths_test, image_labels_train, image_labels_test = (\n",
        "    BigFlareFinder.split_into_train_test_by_time(image_paths, image_labels, test_frac)\n",
        ")\n",
        "\n",
        "# train model\n",
        "big_flare_finder = BigFlareFinder()\n",
        "model = big_flare_finder.fit(image_paths_train, image_labels_train)\n",
        "\n",
        "# get prediction probabilites\n",
        "image_pred_probas_test = big_flare_finder.pred_proba(image_paths_test)\n",
        "print(f\"\\nimage_pred_probas_test: {image_pred_probas_test}\")"
      ],
      "metadata": {
        "id": "fG-qjguPgSzV",
        "outputId": "76373a99-5e92-4002-8ec7-03e6558ee589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch: 0, train_loss: 0.28\n",
            "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
            "Train epoch: 1, train_loss: 0.08\n",
            "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
            "Train epoch: 2, train_loss: 0.05\n",
            "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
            "Train epoch: 3, train_loss: 0.03\n",
            "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
            "Train epoch: 4, train_loss: 0.04\n",
            "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
            "Train epoch: 5, train_loss: 0.03\n",
            "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
            "Train epoch: 6, train_loss: 0.03\n",
            "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
            "Train-on-val epoch: 0, train_loss: 1.94\n",
            "Train-on-val epoch: 1, train_loss: 0.64\n",
            "Train-on-val epoch: 2, train_loss: 0.4\n",
            "Train-on-val epoch: 3, train_loss: 0.17\n",
            "Train-on-val epoch: 4, train_loss: 0.1\n",
            "Train-on-val epoch: 5, train_loss: 0.08\n",
            "Train-on-val epoch: 6, train_loss: 0.06\n",
            "\n",
            "image_pred_probas_test: [np.float32(0.0019624338), np.float32(0.0016745947), np.float32(0.0017453689), np.float32(0.001433507), np.float32(0.001777458), np.float32(0.0017562604), np.float32(0.0009841772), np.float32(0.0013547337), np.float32(0.0011991195), np.float32(0.0022346962), np.float32(0.0032680382), np.float32(0.002121742), np.float32(0.0011912516), np.float32(0.0019378627), np.float32(0.0013430562), np.float32(0.00394264), np.float32(0.0041607087), np.float32(0.003263943), np.float32(0.0031869325), np.float32(0.0019026725), np.float32(0.0032355755), np.float32(0.005234217), np.float32(0.004911696), np.float32(0.0021865186), np.float32(0.005094759), np.float32(0.0046670074), np.float32(0.003468259), np.float32(0.003132822), np.float32(0.0027839628), np.float32(0.0069270693), np.float32(0.006467481), np.float32(0.008987785), np.float32(0.005651263), np.float32(0.0090939235), np.float32(0.012785716), np.float32(0.014152214), np.float32(0.013782946), np.float32(0.012321271), np.float32(0.032080133), np.float32(0.026825765), np.float32(0.024243245), np.float32(0.027080974), np.float32(0.025327507), np.float32(0.017744957), np.float32(0.011575649), np.float32(0.01620938), np.float32(0.01361409), np.float32(0.0055237035), np.float32(0.004598667), np.float32(0.0066853743), np.float32(0.006145765), np.float32(0.008249094), np.float32(0.00925084), np.float32(0.057538178), np.float32(0.11732226), np.float32(0.21296638), np.float32(0.17760254), np.float32(0.13487862), np.float32(0.051078387), np.float32(0.06928049), np.float32(0.07030197), np.float32(0.047622647), np.float32(0.032170415), np.float32(0.025203945), np.float32(0.035759553), np.float32(0.022059025), np.float32(0.014914964), np.float32(0.024943616), np.float32(0.01839861), np.float32(0.018580435), np.float32(0.01697412), np.float32(0.060584273), np.float32(0.029017534), np.float32(0.028736914), np.float32(0.023986131), np.float32(0.0160402), np.float32(0.08058332), np.float32(0.006161574), np.float32(0.004279836), np.float32(0.06955392), np.float32(0.022036847), np.float32(0.020961622), np.float32(0.01134054), np.float32(0.022297591), np.float32(0.18502851), np.float32(0.035379358), np.float32(0.06500434), np.float32(0.016704407), np.float32(0.009303682), np.float32(0.0037182346), np.float32(0.030463822), np.float32(0.03436883), np.float32(0.07418506), np.float32(0.028510178), np.float32(0.04708389), np.float32(0.04301255), np.float32(0.09324027), np.float32(0.043816194), np.float32(0.034306932), np.float32(0.012340551), np.float32(0.017582508), np.float32(0.06696733), np.float32(0.038411956), np.float32(0.015740307), np.float32(0.018009607), np.float32(0.075173005), np.float32(0.030908285), np.float32(0.032410108), np.float32(0.13048978), np.float32(0.11403414), np.float32(0.038810264), np.float32(0.048264068), np.float32(0.037538603), np.float32(0.5878404), np.float32(0.45204017), np.float32(0.39523304), np.float32(0.14084457), np.float32(0.0214104), np.float32(0.35180295), np.float32(0.0053038895), np.float32(0.0055357656), np.float32(0.003276469), np.float32(0.003531356), np.float32(0.0033762143), np.float32(0.02730602), np.float32(0.019943215), np.float32(0.0064224494), np.float32(0.015328716), np.float32(0.003929001), np.float32(0.0034576436), np.float32(0.016427152), np.float32(0.015585423), np.float32(0.041281857), np.float32(0.007999217), np.float32(0.037826393), np.float32(0.017033458), np.float32(0.029042017), np.float32(0.016531853), np.float32(0.0026403242), np.float32(0.011735893), np.float32(0.0058200443), np.float32(0.0019602561), np.float32(0.0038139685), np.float32(0.0009981728), np.float32(0.0013712477), np.float32(0.0007555298), np.float32(0.0010103754), np.float32(0.001406813), np.float32(0.0011726649), np.float32(0.0020349545), np.float32(0.0052959863), np.float32(0.0034993738), np.float32(0.0020111105), np.float32(0.0010406214), np.float32(0.0021647513), np.float32(0.0028870732), np.float32(0.0046803006), np.float32(0.0048217825), np.float32(0.0050743115), np.float32(0.0035721464), np.float32(0.007270655), np.float32(0.0034691454), np.float32(0.004793918), np.float32(0.0036033187), np.float32(0.005804744), np.float32(0.0037047707), np.float32(0.005818467), np.float32(0.0071262987), np.float32(0.019689051), np.float32(0.022088442), np.float32(0.054067668), np.float32(0.027426038), np.float32(0.022872454), np.float32(0.043981273), np.float32(0.020880373), np.float32(0.014022238), np.float32(0.011393376), np.float32(0.013888116), np.float32(0.0145981135), np.float32(0.007132895), np.float32(0.005555214), np.float32(0.011116221), np.float32(0.0074524703), np.float32(0.005230973), np.float32(0.003478032), np.float32(0.007046415), np.float32(0.0057195197), np.float32(0.0023215627), np.float32(0.03043252), np.float32(0.00802921), np.float32(0.009786363), np.float32(0.007192154), np.float32(0.005308332), np.float32(0.004264391), np.float32(0.007744184), np.float32(0.0031179194), np.float32(0.004424743), np.float32(0.0053929784), np.float32(0.003467771), np.float32(0.0022616114), np.float32(0.00096833386), np.float32(0.0035217798), np.float32(0.006069897), np.float32(0.007975433), np.float32(0.001405956), np.float32(0.005395531), np.float32(0.0037985784), np.float32(0.004476569), np.float32(0.013582666), np.float32(0.00671999), np.float32(0.0070679677), np.float32(0.008667918), np.float32(0.019097522), np.float32(0.0127324145), np.float32(0.008029476), np.float32(0.0132894665), np.float32(0.0031042018), np.float32(0.01095936), np.float32(0.0054888786), np.float32(0.008357597)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get performance of model on test data\n",
        "\n",
        "# get the image data: image_paths, image_labels\n",
        "image_folder_path = f\"{path_to_coderepo}/../../data/sdo_images_w=131a\"\n",
        "big_flare_labels_df = pd.read_csv(f\"{image_folder_path}/big_flare_labels.csv\").dropna()\n",
        "\n",
        "# [TEMP] shorten big_flare_labels_df\n",
        "big_flare_labels_df = big_flare_labels_df.sort_values('solar_image_filename').iloc[None:1000]\n",
        "\n",
        "image_paths = (\n",
        "    image_folder_path + \"/\" + big_flare_labels_df[\"solar_image_filename\"]\n",
        ").to_list()\n",
        "image_labels = big_flare_labels_df[\"is_big_flare\"].to_list()\n",
        "\n",
        "# split image_paths and image_labels by time:\n",
        "#     image_paths_train, image_paths_test, image_labels_train, image_labels_test\n",
        "test_frac = 0.5\n",
        "image_paths_train, image_paths_test, image_labels_train, image_labels_test = (\n",
        "    BigFlareFinder.split_into_train_test_by_time(image_paths, image_labels, test_frac)\n",
        ")\n",
        "\n",
        "# train model\n",
        "big_flare_finder = BigFlareFinder()\n",
        "model = big_flare_finder.fit(image_paths_train, image_labels_train)\n",
        "\n",
        "# make predictions\n",
        "image_labels_test_pred = big_flare_finder.predict(image_paths_test)\n",
        "\n",
        "# get pred metrics\n",
        "test_metrics = BigFlareFinder.get_model_performance_metrics(image_labels_test, image_labels_test_pred)\n",
        "print(f\"\\ntest_metrics: {test_metrics}\")"
      ],
      "metadata": {
        "id": "42BpT1U1e2Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot histogram of big flares as a function of month\n",
        "\n",
        "# set the style of plotting to seaborn whitegrid\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# get the image data: image_paths, image_labels\n",
        "image_folder_path = f\"{path_to_coderepo}/../../data/sdo_images_w=131a\"\n",
        "big_flare_labels_df = pd.read_csv(f\"{image_folder_path}/big_flare_labels.csv\").dropna().sort_values('solar_image_filename')\n",
        "\n",
        "# get datetime from solar_image_filename in big_flare_labels_df\n",
        "big_flare_labels_df['datetime'] = pd.to_datetime(big_flare_labels_df['solar_image_filename'].str.split('.').str[0], errors = 'coerce')\n",
        "\n",
        "# bin datetime to first day of month\n",
        "big_flare_labels_df['date_bin'] = big_flare_labels_df['datetime'].dt.to_period('M').dt.to_timestamp()\n",
        "\n",
        "# groupby date_bin and sum is_big_flare\n",
        "# rotate the x axis labels\n",
        "ax = big_flare_labels_df.groupby('date_bin')['is_big_flare'].sum().plot(kind='bar')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "_ = ax.set_xticklabels([label.get_text()[:10] for label in ax.get_xticklabels()])"
      ],
      "metadata": {
        "id": "1S4VKMRHzNH1",
        "outputId": "833e1962-0d6f-4810-c3f6-f9cb645ca825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modify pred to output probabilities and rename it is predict_proba\n",
        "# test on the small dataset"
      ],
      "metadata": {
        "id": "VkG1Mrg-WxF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dunZPQke0MXB"
      },
      "outputs": [],
      "source": [
        "# train big-flare classifier\n",
        "# * train big-flare classifier on first 70% of 2015 and test on last 30%\n",
        "# * show prediction-quality (accuracy, f1, precn, recall)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAmWCvgkS7je"
      },
      "outputs": [],
      "source": [
        "# show the timeline of flares in test along with predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yntWKplVS9qk"
      },
      "outputs": [],
      "source": [
        "# show what the model learned\n",
        "# * some viz of features picked up by the model for big-flares"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}