{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishstronomer/flare-finder/blob/main/flare_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xZ5d83BIX0Jl",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5050b536-30b0-4e6d-bb88-5a946d038bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (2023.8.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (3.7.1)\n",
            "Collecting s3fs (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4))\n",
            "  Downloading s3fs-2024.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting sunpy (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5))\n",
            "  Downloading sunpy-5.1.3-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zarr (from -r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6))\n",
            "  Downloading zarr-2.18.2-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.2/210.2 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (24.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (7.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (2.8.2)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4))\n",
            "  Downloading aiobotocore-2.13.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2021.09.0 (from dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (3.9.5)\n",
            "Requirement already satisfied: astropy!=5.1.0,>=5.0.6 in /usr/local/lib/python3.10/dist-packages (from sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (5.3.4)\n",
            "Collecting parfive[ftp]>=2.0.0 (from sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5))\n",
            "  Downloading parfive-2.1.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pyerfa in /usr/local/lib/python3.10/dist-packages (from sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (2.0.1.4)\n",
            "Collecting asciitree (from zarr->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6))\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numcodecs>=0.10.0 (from zarr->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6))\n",
            "  Downloading numcodecs-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners (from zarr->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 6))\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Collecting botocore<1.34.107,>=1.34.70 (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4))\n",
            "  Downloading botocore-1.34.106-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.14.1)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4))\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (3.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from parfive[ftp]>=2.0.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5)) (4.66.4)\n",
            "Collecting aioftp>=0.17.1 (from parfive[ftp]>=2.0.0->sunpy->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 5))\n",
            "  Downloading aioftp-0.22.3-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 3)) (1.16.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.34.107,>=1.34.70->aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.107,>=1.34.70->aiobotocore<3.0.0,>=2.5.4->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->-r /content/drive/MyDrive/ML_project/code_repo/flare-finder/requirements.txt (line 4)) (3.7)\n",
            "Building wheels for collected packages: asciitree\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5034 sha256=8443af562f8a6f5c092591a3ed486e76d556064b16aa3d8698f66ea6fb52b4eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\n",
            "Successfully built asciitree\n",
            "Installing collected packages: asciitree, numcodecs, jmespath, fsspec, fasteners, aioitertools, aioftp, zarr, botocore, parfive, aiobotocore, s3fs, sunpy\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.0+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiobotocore-2.13.0 aioftp-0.22.3 aioitertools-0.11.0 asciitree-0.3.3 botocore-1.34.106 fasteners-0.19 fsspec-2024.5.0 jmespath-1.0.1 numcodecs-0.12.1 parfive-2.1.0 s3fs-2024.5.0 sunpy-5.1.3 zarr-2.18.2\n"
          ]
        }
      ],
      "source": [
        "# set globals\n",
        "\n",
        "# do Google Colab things\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# install dependencies\n",
        "path_to_coderepo = (\n",
        "    \"/content/drive/MyDrive/ML_project/code_repo/flare-finder\" if IN_COLAB else \".\"\n",
        ")\n",
        "if IN_COLAB:\n",
        "    !pip install -r {path_to_coderepo}/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set globals\n",
        "\n",
        "# import standard libraries\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "A-aj79jI1cYr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DNmcTVnQ0MXA"
      },
      "outputs": [],
      "source": [
        "# creating model class for big flare prediction\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class BigFlareFinder:\n",
        "    def __init__(self):\n",
        "        self.pytorch_model = None\n",
        "\n",
        "    def fit(self, image_paths, image_labels, val_frac=0.2):\n",
        "\n",
        "        # split the data into train-validation using sklearn and use stratified sampling\n",
        "        image_paths_train, image_paths_val, image_labels_train, image_labels_val = train_test_split(\n",
        "            image_paths, image_labels, test_size=val_frac, random_state=42, stratify=image_labels)\n",
        "\n",
        "        # get dataloader for train and validation data\n",
        "\n",
        "        train_loader = BigFlareFinder.preprocess(image_paths_train, image_labels_train)\n",
        "        validation_loader = BigFlareFinder.preprocess(image_paths_val, image_labels_val)\n",
        "\n",
        "        # fit pytorch model using dataloader\n",
        "\n",
        "        return train_loader, validation_loader\n",
        "\n",
        "    def predict(self, image_paths):\n",
        "        image_labels = [0] * (len(image_paths))\n",
        "        return image_labels\n",
        "\n",
        "    @staticmethod\n",
        "    def get_model_performance_metrics(y_true, y_pred):\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "        metrics_dict = {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"precision_class_1\": precision,\n",
        "            \"recall_class_1\": recall,\n",
        "        }\n",
        "        return metrics_dict\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(image_paths, image_labels):\n",
        "        # make dataset of image_paths and image_labels\n",
        "        image_dimension = 224\n",
        "        image_transforms = transforms.Compose([\n",
        "            transforms.Resize((image_dimension, image_dimension)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
        "            ])\n",
        "        dataset = CustomImageDataset(image_paths, image_labels, image_transforms)\n",
        "\n",
        "        # make dataloader for dataset\n",
        "        batch_size = 32\n",
        "        num_workers = 2\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "        return dataloader\n",
        "\n",
        "\n",
        "# run the model on some data\n",
        "\n",
        "# get image paths and labels\n",
        "notbigflare_max_count = 900\n",
        "bigflare_max_count = 100\n",
        "image_folder_path = f\"{path_to_coderepo}/../../data/sdo_images\"\n",
        "solar_image_path_df = pd.read_csv(f\"{path_to_coderepo}/big_flare_labels.csv\").dropna()\n",
        "solar_image_path_df = pd.concat(\n",
        "    [\n",
        "        solar_image_path_df[solar_image_path_df[\"is_big_flare\"] == 0][0:notbigflare_max_count],\n",
        "        solar_image_path_df[solar_image_path_df[\"is_big_flare\"] == 1][0:bigflare_max_count],\n",
        "    ]\n",
        ")\n",
        "image_paths = (image_folder_path + '/' + solar_image_path_df['solar_image_filename']).to_list()\n",
        "image_labels = solar_image_path_df['is_big_flare'].to_list()\n",
        "\n",
        "# split data into train-test using sklearn and use stratified sampling\n",
        "image_paths_train, image_paths_test, image_labels_train, image_labels_test = train_test_split(\n",
        "    image_paths, image_labels, test_size=0.2, random_state=42, stratify=image_labels\n",
        ")\n",
        "\n",
        "# train model\n",
        "big_flare_finder = BigFlareFinder()\n",
        "dataset, dataloader = big_flare_finder.fit(image_paths_train, image_labels_train)\n",
        "\n",
        "# # test model on test data\n",
        "# image_labels_test_pred =  big_flare_finder.predict(image_paths_test)\n",
        "# metrics_dict = big_flare_finder.get_model_performance_metrics(image_labels_test, image_labels_test_pred)\n",
        "# print(metrics_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOoMxH130MXB",
        "outputId": "952e8a36-0ca7-4698-acdf-34b0b52b61bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7dcfe4637370>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7dcfe4636d70>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dunZPQke0MXB",
        "outputId": "3a0c9d4a-7a9e-479c-da9f-6c5b463ed823"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "is_big_flare\n",
              "0.0    6109\n",
              "NaN    2323\n",
              "1.0     118\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test[\"is_big_flare\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2k7AsMIf5hz"
      },
      "outputs": [],
      "source": [
        "import os, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-paKGyugBOl"
      },
      "outputs": [],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sbM4RjXgGfL"
      },
      "outputs": [],
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSHaKbNsatfZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path_to_data = '/content/drive/My Drive/ML_project/data/sdo_images/'\n",
        "big_flare_labels_filename = 'big_flare_labels.csv'\n",
        "big_flare_labels_filpepath = os.path.join(path_to_data, big_flare_labels_filename)\n",
        "solar_image_path_df = pd.read_csv(big_flare_labels_filpepath)\n",
        "big_flare_paths = solar_image_path_df[solar_image_path_df['is_big_flare'] == 1]['solar_image_filename'].apply(lambda x: os.path.join(path_to_data, x)).tolist()\n",
        "not_big_flare_paths = solar_image_path_df[solar_image_path_df['is_big_flare'] == 0]['solar_image_filename'].apply(lambda x: os.path.join(path_to_data, x)).tolist()\n",
        "\n",
        "len(big_flare_paths), len(not_big_flare_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uBlMZTXteCV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhbq0eCQCiJX"
      },
      "outputs": [],
      "source": [
        "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
        "model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G04jSIbapqB7"
      },
      "outputs": [],
      "source": [
        "# Freeze all params except the BatchNorm layers, as here they are trained to the\n",
        "# mean and standard deviation of ImageNet and we may lose some signal\n",
        "for name, param in model_resnet18.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "        param.requires_grad = False\n",
        "\n",
        "for name, param in model_resnet34.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tCK34rmprqJ"
      },
      "outputs": [],
      "source": [
        "# Replace the classifier\n",
        "num_classes = 2\n",
        "\n",
        "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(),\n",
        "                                  nn.Linear(512, num_classes))\n",
        "\n",
        "model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(),\n",
        "                                  nn.Linear(512, num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YHzSGDoqYMZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\", target_class=1):\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "        all_targets = []\n",
        "        all_predictions = []\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output,targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)[1]\n",
        "            correct = torch.eq(predictions, targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "\n",
        "        # Calculate precision and recall for the target class\n",
        "        precision = precision_score(all_targets, all_predictions, pos_label=target_class, average='binary', zero_division=0)\n",
        "        recall = recall_score(all_targets, all_predictions, pos_label=target_class, average='binary', zero_division=0)\n",
        "\n",
        "        # Debug statements\n",
        "        print(f\"Targets distribution: {dict(zip(*np.unique(all_targets, return_counts=True)))}\")\n",
        "        print(f\"Predictions distribution: {dict(zip(*np.unique(all_predictions, return_counts=True)))}\")\n",
        "\n",
        "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}'.format(\n",
        "            epoch, training_loss, valid_loss, num_correct / num_examples, precision, recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSyN5BIGtWJV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "paths_class1 = not_big_flare_paths[:70]\n",
        "paths_class2 = big_flare_paths[:30]\n",
        "split_fractions = [0.7, 0.1, 0.2]\n",
        "\n",
        "def get_dataloaders(paths_class1, paths_class2, split_fractions):\n",
        "  # split the paths list into subsets for class 1 and class 2\n",
        "  paths_class1_split = [list(subset) for subset in random_split(paths_class1, split_fractions)]\n",
        "  paths_class2_split = [list(subset) for subset in random_split(paths_class2, split_fractions)]\n",
        "\n",
        "  # defining inputs to the DataLoader function\n",
        "  img_dimensions = 224\n",
        "  img_transforms = transforms.Compose([\n",
        "      transforms.Resize((img_dimensions, img_dimensions)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
        "      ])\n",
        "  batch_size = 32\n",
        "  num_workers = 2\n",
        "\n",
        "  # function to get dataloader from class subsets\n",
        "  def get_dataloader(class1_subset, class2_subset):\n",
        "    all_subset = class1_subset + class2_subset\n",
        "    class1_subset_labels = len(class1_subset)*[0]\n",
        "    class2_subset_labels = len(class2_subset)*[1]\n",
        "    all_subset_labels = class1_subset_labels + class2_subset_labels\n",
        "    subset_dataset = CustomImageDataset(all_subset, all_subset_labels, transform=img_transforms)\n",
        "    subset_dataloader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    return subset_dataloader\n",
        "\n",
        "  data_loaders = [get_dataloader(class1_subset, class2_subset) for class1_subset, class2_subset in zip(paths_class1_split, paths_class2_split)]\n",
        "\n",
        "  return data_loaders\n",
        "\n",
        "train_data_loader, validation_data_loader, test_data_loader = get_dataloaders(paths_class1, paths_class2, split_fractions)\n",
        "train_data_loader, validation_data_loader, test_data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUZLNnqXuFVd"
      },
      "outputs": [],
      "source": [
        "print(f'Num training images: {len(train_data_loader.dataset)}')\n",
        "print(f'Num validation images: {len(validation_data_loader.dataset)}')\n",
        "print(f'Num test images: {len(test_data_loader.dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDASReG_xND1"
      },
      "source": [
        "## Train and test the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip3bkjFBpIKn"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_data_loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('correct: {:d}  total: {:d}'.format(correct, total))\n",
        "    print('accuracy = {:f}'.format(correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTuZrmWFiV5r"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3ED44qupQbE"
      },
      "outputs": [],
      "source": [
        "model_resnet18.to(device)\n",
        "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
        "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaB7QTvDlW3o"
      },
      "source": [
        "Targets distribution: {0: 7, 1: 3} that in the validation set, there are 7 instances of class 0 and 3 instances of class 1. This tells you the actual distribution of classes in your validation data.\n",
        "\n",
        "Predictions distribution: {0: 9, 1: 1} indicates that the model predicted 9 instances as class 0 and 1 instance as class 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CVZcFCZpVUo"
      },
      "outputs": [],
      "source": [
        "test_model(model_resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRnMrbZ3LWAh"
      },
      "outputs": [],
      "source": [
        "model_resnet34.to(device)\n",
        "optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
        "train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZTBo5WGOt-G"
      },
      "outputs": [],
      "source": [
        "test_model(model_resnet34)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onqu63K-ldJ9"
      },
      "source": [
        "## Make some predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRT-cyxpUGWx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def find_classes(dir):\n",
        "    classes = os.listdir(dir)\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "def make_prediction(model, filename):\n",
        "    labels, _ = find_classes('/content/drive/My Drive/ML_project/dogs-vs-cats/test')\n",
        "    img = Image.open(filename)\n",
        "    img = img_test_transforms(img)\n",
        "    img = img.unsqueeze(0)\n",
        "    prediction = model(img.to(device))\n",
        "    prediction = prediction.argmax()\n",
        "    print(labels[prediction])\n",
        "\n",
        "# make_prediction(model_resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/dogs/dog.1146.jpg')\n",
        "# make_prediction(model_resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/cats/cat.1226.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhu_7CTZlcOv"
      },
      "outputs": [],
      "source": [
        "torch.save(model_resnet18.state_dict(), \"./model_resnet18.pth\")\n",
        "torch.save(model_resnet34.state_dict(), \"./model_resnet34.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1AkEtXxsBX"
      },
      "source": [
        "## Load the models from disk and test with an ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbtpycTSxn5j"
      },
      "outputs": [],
      "source": [
        "# Remember that you must call model.eval() to set dropout and batch normalization layers to\n",
        "# evaluation mode before running inference. Failing to do this will yield inconsistent inference result\n",
        "\n",
        "resnet18 = torch.hub.load('pytorch/vision', 'resnet18')\n",
        "resnet18.fc = nn.Sequential(nn.Linear(resnet18.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
        "resnet18.load_state_dict(torch.load('./model_resnet18.pth'))\n",
        "resnet18.eval()\n",
        "\n",
        "resnet34 = torch.hub.load('pytorch/vision', 'resnet34')\n",
        "resnet34.fc = nn.Sequential(nn.Linear(resnet34.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
        "resnet34.load_state_dict(torch.load('./model_resnet34.pth'))\n",
        "resnet34.eval()\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKKYcCuRxzOw"
      },
      "outputs": [],
      "source": [
        "# Test against the average of each prediction from the two models\n",
        "models_ensemble = [resnet18.to(device), resnet34.to(device)]\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_data_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        predictions = [i(images).data for i in models_ensemble]\n",
        "        avg_predictions = torch.mean(torch.stack(predictions), dim=0)\n",
        "        _, predicted = torch.max(avg_predictions, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('accuracy = {:f}'.format(correct / total))\n",
        "print('correct: {:d}  total: {:d}'.format(correct, total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZABx-YIx4Ea"
      },
      "outputs": [],
      "source": [
        "# Assuming your model and data are on the same device (e.g., 'cuda' or 'cpu')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet34.to(device)\n",
        "\n",
        "# Example usage\n",
        "make_prediction(resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/dogs/dog.1146.jpg')\n",
        "make_prediction(resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/cats/cat.1226.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZJMyJu0zhEu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}