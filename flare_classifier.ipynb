{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishstronomer/flare-finder/blob/main/flare_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xZ5d83BIX0Jl"
      },
      "outputs": [],
      "source": [
        "# set globals\n",
        "\n",
        "# do Google Colab things\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# install dependencies\n",
        "path_to_coderepo = (\n",
        "    \"/content/drive/MyDrive/ML_project/code_repo/flare-finder\" if IN_COLAB else \".\"\n",
        ")\n",
        "if IN_COLAB:\n",
        "    !pip install -r {path_to_coderepo}/requirements.txt\n",
        "\n",
        "# import standard libraries\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.9, 'precision': 0.0, 'recall': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aishsk6/anaconda3/envs/mlproject/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# creating model class for big flare prediction\n",
        "\n",
        "\n",
        "class BigFlareFinder:\n",
        "    def __init__(self):\n",
        "        self.pytorch_model = None\n",
        "\n",
        "    def fit(self, image_paths, image_labels, val_frac=0.2):\n",
        "\n",
        "        # make dataset of image_paths and image_labels\n",
        "\n",
        "        # make dataloader for dataset\n",
        "\n",
        "        # fit pytorch model using dataloader\n",
        "\n",
        "\n",
        "\n",
        "        return None\n",
        "\n",
        "    def predict(self, image_paths):\n",
        "        image_labels = [0] * (len(image_paths))\n",
        "        return image_labels\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_model_performance_metrics(y_true, y_pred):\n",
        "        accuracy = accuracy_score(image_labels_test, image_labels_test_pred)\n",
        "        precision = precision_score(image_labels_test, image_labels_test_pred)\n",
        "        recall = recall_score(image_labels_test, image_labels_test_pred)\n",
        "        metrics_dict = {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "        }\n",
        "        return metrics_dict\n",
        "\n",
        "\n",
        "# run the model on some data\n",
        "\n",
        "# get image paths and labels\n",
        "notbigflare_max_count = 900\n",
        "bigflare_max_count = 100\n",
        "image_folder_path = f\"{path_to_coderepo}/../../ML_project/data/sdo_images\"\n",
        "solar_image_path_df = pd.read_csv(\"big_flare_labels.csv\").dropna()\n",
        "solar_image_path_df = pd.concat(\n",
        "    [\n",
        "        solar_image_path_df[solar_image_path_df[\"is_big_flare\"] == 0][0:notbigflare_max_count],\n",
        "        solar_image_path_df[solar_image_path_df[\"is_big_flare\"] == 1][0:bigflare_max_count],\n",
        "    ]\n",
        ")\n",
        "image_paths = (image_folder_path + '/' + solar_image_path_df['solar_image_filename']).to_list()\n",
        "image_labels = solar_image_path_df['is_big_flare'].to_list()\n",
        "\n",
        "# split data into train-test using sklearn and use stratified sampling\n",
        "image_paths_train, image_paths_test, image_labels_train, image_labels_test = train_test_split(\n",
        "    image_paths, image_labels, test_size=0.2, random_state=42, stratify=image_labels\n",
        ")\n",
        "\n",
        "# train model\n",
        "big_flare_finder = BigFlareFinder()\n",
        "big_flare_finder.fit(image_paths_train, image_labels_train)\n",
        "\n",
        "# test model on test data\n",
        "image_labels_test_pred =  big_flare_finder.predict(image_paths_test)\n",
        "metrics_dict = big_flare_finder.get_model_performance_metrics(image_labels_test, image_labels_test_pred)\n",
        "print(metrics_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "is_big_flare\n",
              "0.0    6109\n",
              "NaN    2323\n",
              "1.0     118\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test[\"is_big_flare\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2k7AsMIf5hz"
      },
      "outputs": [],
      "source": [
        "import os, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-paKGyugBOl",
        "outputId": "52a86a89-7061-4c66-be09-6c30388bb9f2"
      },
      "outputs": [],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sbM4RjXgGfL",
        "outputId": "5f380072-8fa1-4770-991a-7fd8a18497ce"
      },
      "outputs": [],
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSHaKbNsatfZ",
        "outputId": "d6f14be2-0f5b-46d9-83b2-1bcecfaec31a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path_to_data = '/content/drive/My Drive/ML_project/data/sdo_images/'\n",
        "big_flare_labels_filename = 'big_flare_labels.csv'\n",
        "big_flare_labels_filpepath = os.path.join(path_to_data, big_flare_labels_filename)\n",
        "solar_image_path_df = pd.read_csv(big_flare_labels_filpepath)\n",
        "big_flare_paths = solar_image_path_df[solar_image_path_df['is_big_flare'] == 1]['solar_image_filename'].apply(lambda x: os.path.join(path_to_data, x)).tolist()\n",
        "not_big_flare_paths = solar_image_path_df[solar_image_path_df['is_big_flare'] == 0]['solar_image_filename'].apply(lambda x: os.path.join(path_to_data, x)).tolist()\n",
        "\n",
        "len(big_flare_paths), len(not_big_flare_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uBlMZTXteCV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhbq0eCQCiJX",
        "outputId": "67dfb90b-3042-469b-c769-2c687f9aeca7"
      },
      "outputs": [],
      "source": [
        "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
        "model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G04jSIbapqB7"
      },
      "outputs": [],
      "source": [
        "# Freeze all params except the BatchNorm layers, as here they are trained to the\n",
        "# mean and standard deviation of ImageNet and we may lose some signal\n",
        "for name, param in model_resnet18.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "        param.requires_grad = False\n",
        "\n",
        "for name, param in model_resnet34.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tCK34rmprqJ"
      },
      "outputs": [],
      "source": [
        "# Replace the classifier\n",
        "num_classes = 2\n",
        "\n",
        "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(),\n",
        "                                  nn.Linear(512, num_classes))\n",
        "\n",
        "model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(),\n",
        "                                  nn.Linear(512, num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YHzSGDoqYMZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\", target_class=1):\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "        all_targets = []\n",
        "        all_predictions = []\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output,targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)[1]\n",
        "            correct = torch.eq(predictions, targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "\n",
        "        # Calculate precision and recall for the target class\n",
        "        precision = precision_score(all_targets, all_predictions, pos_label=target_class, average='binary', zero_division=0)\n",
        "        recall = recall_score(all_targets, all_predictions, pos_label=target_class, average='binary', zero_division=0)\n",
        "\n",
        "        # Debug statements\n",
        "        print(f\"Targets distribution: {dict(zip(*np.unique(all_targets, return_counts=True)))}\")\n",
        "        print(f\"Predictions distribution: {dict(zip(*np.unique(all_predictions, return_counts=True)))}\")\n",
        "\n",
        "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}'.format(\n",
        "            epoch, training_loss, valid_loss, num_correct / num_examples, precision, recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSyN5BIGtWJV",
        "outputId": "d64993a9-1093-40db-b2b0-026eafc13693"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "paths_class1 = not_big_flare_paths[:70]\n",
        "paths_class2 = big_flare_paths[:30]\n",
        "split_fractions = [0.7, 0.1, 0.2]\n",
        "\n",
        "def get_dataloaders(paths_class1, paths_class2, split_fractions):\n",
        "  # split the paths list into subsets for class 1 and class 2\n",
        "  paths_class1_split = [list(subset) for subset in random_split(paths_class1, split_fractions)]\n",
        "  paths_class2_split = [list(subset) for subset in random_split(paths_class2, split_fractions)]\n",
        "\n",
        "  # defining inputs to the DataLoader function\n",
        "  img_dimensions = 224\n",
        "  img_transforms = transforms.Compose([\n",
        "      transforms.Resize((img_dimensions, img_dimensions)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
        "      ])\n",
        "  batch_size = 32\n",
        "  num_workers = 2\n",
        "\n",
        "  # function to get dataloader from class subsets\n",
        "  def get_dataloader(class1_subset, class2_subset):\n",
        "    all_subset = class1_subset + class2_subset\n",
        "    class1_subset_labels = len(class1_subset)*[0]\n",
        "    class2_subset_labels = len(class2_subset)*[1]\n",
        "    all_subset_labels = class1_subset_labels + class2_subset_labels\n",
        "    subset_dataset = CustomImageDataset(all_subset, all_subset_labels, transform=img_transforms)\n",
        "    subset_dataloader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    return subset_dataloader\n",
        "\n",
        "  data_loaders = [get_dataloader(class1_subset, class2_subset) for class1_subset, class2_subset in zip(paths_class1_split, paths_class2_split)]\n",
        "\n",
        "  return data_loaders\n",
        "\n",
        "train_data_loader, validation_data_loader, test_data_loader = get_dataloaders(paths_class1, paths_class2, split_fractions)\n",
        "train_data_loader, validation_data_loader, test_data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUZLNnqXuFVd",
        "outputId": "e7ffbe3d-9ca0-4c44-dc0b-0c24a2fb464c"
      },
      "outputs": [],
      "source": [
        "print(f'Num training images: {len(train_data_loader.dataset)}')\n",
        "print(f'Num validation images: {len(validation_data_loader.dataset)}')\n",
        "print(f'Num test images: {len(test_data_loader.dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDASReG_xND1"
      },
      "source": [
        "## Train and test the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip3bkjFBpIKn"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_data_loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('correct: {:d}  total: {:d}'.format(correct, total))\n",
        "    print('accuracy = {:f}'.format(correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTuZrmWFiV5r"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ED44qupQbE",
        "outputId": "f2af0bd7-f301-41dc-f9f9-508d91888250"
      },
      "outputs": [],
      "source": [
        "model_resnet18.to(device)\n",
        "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
        "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaB7QTvDlW3o"
      },
      "source": [
        "Targets distribution: {0: 7, 1: 3} that in the validation set, there are 7 instances of class 0 and 3 instances of class 1. This tells you the actual distribution of classes in your validation data.\n",
        "\n",
        "Predictions distribution: {0: 9, 1: 1} indicates that the model predicted 9 instances as class 0 and 1 instance as class 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CVZcFCZpVUo",
        "outputId": "407f8198-74e1-4698-c83d-a57d22168684"
      },
      "outputs": [],
      "source": [
        "test_model(model_resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRnMrbZ3LWAh",
        "outputId": "c53627d3-c3d8-458f-e492-811ef5fee621"
      },
      "outputs": [],
      "source": [
        "model_resnet34.to(device)\n",
        "optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
        "train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZTBo5WGOt-G",
        "outputId": "bfdf6962-f768-4e70-f8a9-16c49acac0cb"
      },
      "outputs": [],
      "source": [
        "test_model(model_resnet34)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onqu63K-ldJ9"
      },
      "source": [
        "## Make some predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRT-cyxpUGWx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def find_classes(dir):\n",
        "    classes = os.listdir(dir)\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "def make_prediction(model, filename):\n",
        "    labels, _ = find_classes('/content/drive/My Drive/ML_project/dogs-vs-cats/test')\n",
        "    img = Image.open(filename)\n",
        "    img = img_test_transforms(img)\n",
        "    img = img.unsqueeze(0)\n",
        "    prediction = model(img.to(device))\n",
        "    prediction = prediction.argmax()\n",
        "    print(labels[prediction])\n",
        "\n",
        "# make_prediction(model_resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/dogs/dog.1146.jpg')\n",
        "# make_prediction(model_resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/cats/cat.1226.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhu_7CTZlcOv"
      },
      "outputs": [],
      "source": [
        "torch.save(model_resnet18.state_dict(), \"./model_resnet18.pth\")\n",
        "torch.save(model_resnet34.state_dict(), \"./model_resnet34.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1AkEtXxsBX"
      },
      "source": [
        "## Load the models from disk and test with an ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "zbtpycTSxn5j",
        "outputId": "b8837fc5-ef8f-45fd-8b24-545b9a407e77"
      },
      "outputs": [],
      "source": [
        "# Remember that you must call model.eval() to set dropout and batch normalization layers to\n",
        "# evaluation mode before running inference. Failing to do this will yield inconsistent inference result\n",
        "\n",
        "resnet18 = torch.hub.load('pytorch/vision', 'resnet18')\n",
        "resnet18.fc = nn.Sequential(nn.Linear(resnet18.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
        "resnet18.load_state_dict(torch.load('./model_resnet18.pth'))\n",
        "resnet18.eval()\n",
        "\n",
        "resnet34 = torch.hub.load('pytorch/vision', 'resnet34')\n",
        "resnet34.fc = nn.Sequential(nn.Linear(resnet34.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
        "resnet34.load_state_dict(torch.load('./model_resnet34.pth'))\n",
        "resnet34.eval()\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKKYcCuRxzOw",
        "outputId": "8e12be95-fa5c-46c5-cdd4-17de538f8ef1"
      },
      "outputs": [],
      "source": [
        "# Test against the average of each prediction from the two models\n",
        "models_ensemble = [resnet18.to(device), resnet34.to(device)]\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_data_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        predictions = [i(images).data for i in models_ensemble]\n",
        "        avg_predictions = torch.mean(torch.stack(predictions), dim=0)\n",
        "        _, predicted = torch.max(avg_predictions, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('accuracy = {:f}'.format(correct / total))\n",
        "print('correct: {:d}  total: {:d}'.format(correct, total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZABx-YIx4Ea",
        "outputId": "4d1d8d33-b12d-4855-e06e-68e268f9a41e"
      },
      "outputs": [],
      "source": [
        "# Assuming your model and data are on the same device (e.g., 'cuda' or 'cpu')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet34.to(device)\n",
        "\n",
        "# Example usage\n",
        "make_prediction(resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/dogs/dog.1146.jpg')\n",
        "make_prediction(resnet34, '/content/drive/My Drive/ML_project/dogs-vs-cats/test/cats/cat.1226.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZJMyJu0zhEu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPFiZ1ebV9dj4IsyQJWFW66",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
