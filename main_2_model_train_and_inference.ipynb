{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "xZ5d83BIX0Jl",
    "outputId": "837d3f4e-2e79-484a-d463-4db73c4a40a6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_coderepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/src\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m     26\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_coderepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/src\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbig_flare_finder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BigFlareFinder\n",
      "File \u001b[0;32m~/My Drive/ML_project/code_repo/flare-finder/src/big_flare_finder.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recall_score\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet18_Weights\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# set globals\n",
    "\n",
    "# do Google Colab things\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# install dependencies\n",
    "path_to_coderepo = (\n",
    "    \"/content/drive/MyDrive/ML_project/code_repo/flare-finder\" if IN_COLAB else \".\"\n",
    ")\n",
    "if IN_COLAB:\n",
    "    !pip install -r {path_to_coderepo}/requirements.txt\n",
    "\n",
    "# import standard libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# import custom libraries\n",
    "if f'{path_to_coderepo}/src' not in sys.path:\n",
    "    sys.path.append(f'{path_to_coderepo}/src')\n",
    "from big_flare_finder import BigFlareFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DNmcTVnQ0MXA"
   },
   "outputs": [],
   "source": [
    "# creating model class for big flare prediction\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pdb\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class BigFlareFinder:\n",
    "    def __init__(self):\n",
    "\n",
    "        # init pytorch model\n",
    "        self.pytorch_model = None\n",
    "\n",
    "        # set things to make training deterministic\n",
    "        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "        torch.manual_seed(42)\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "        # set device\n",
    "        self.device = None\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "    def fit(self, image_paths, image_labels, val_frac=0.5):\n",
    "\n",
    "        # split the data into train and validation using time\n",
    "        image_paths_train, image_paths_val, image_labels_train, image_labels_val = (\n",
    "            BigFlareFinder.split_into_train_test_by_time(image_paths, image_labels, val_frac)\n",
    "        )\n",
    "\n",
    "        # for training, augment minority-class by making copies\n",
    "        image_paths_train, image_labels_train = BigFlareFinder.augment_minority_class(\n",
    "            image_paths_train, image_labels_train\n",
    "        )\n",
    "\n",
    "        # get dataloader for train and validation data\n",
    "        train_loader = BigFlareFinder.preprocess(image_paths_train, image_labels_train)\n",
    "        validation_loader = BigFlareFinder.preprocess(image_paths_val, image_labels_val)\n",
    "\n",
    "        # fit pytorch model using dataloader\n",
    "\n",
    "        # load resnet18 model\n",
    "        # model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "        model_resnet18 = torch.hub.load(\n",
    "            \"pytorch/vision\", \"resnet18\", weights=ResNet18_Weights.DEFAULT\n",
    "        )\n",
    "\n",
    "        # Freeze all params except the BatchNorm layers, as here they are trained to the\n",
    "        # mean and standard deviation of ImageNet and we may lose some signal\n",
    "        for name, param in model_resnet18.named_parameters():\n",
    "            if \"bn\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # reduce number of output classes in model\n",
    "        num_classes = 2\n",
    "        model_resnet18.fc = nn.Sequential(\n",
    "            nn.Linear(model_resnet18.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "        model_resnet18.to(self.device)\n",
    "        optimizer = optim.Adam(model_resnet18.parameters())\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        epochs = 7  # 10\n",
    "        target_class = 1\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            training_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            model_resnet18.train()\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                inputs, targets = batch\n",
    "                targets = targets.type(torch.LongTensor)\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                output = model_resnet18(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.data.item() * inputs.size(0)\n",
    "            training_loss /= len(train_loader.dataset)\n",
    "\n",
    "            model_resnet18.eval()\n",
    "            # all_targets = []\n",
    "            image_labels_val_pred = []\n",
    "\n",
    "            for batch in validation_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(self.device)\n",
    "                output = model_resnet18(inputs)\n",
    "                predictions = torch.max(F.softmax(output, dim=1), dim=1)[1]\n",
    "                image_labels_val_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "            print(\n",
    "                f\"Train epoch: {epoch}\"\n",
    "                f\", train_loss: {round(training_loss, 2)}\"\n",
    "                f\"\\nval_metrics: {BigFlareFinder.get_model_performance_metrics(image_labels_val, image_labels_val_pred)}\"\n",
    "            )\n",
    "\n",
    "        # train on the val data (which was excluded from training earlier)\n",
    "        image_paths_val, image_labels_val = BigFlareFinder.augment_minority_class(\n",
    "            image_paths_val, image_labels_val\n",
    "        )\n",
    "        val_loader = BigFlareFinder.preprocess(image_paths_val, image_labels_val)\n",
    "        for epoch in range(epochs):\n",
    "            for batch in val_loader:\n",
    "                optimizer.zero_grad()\n",
    "                inputs, targets = batch\n",
    "                targets = targets.type(torch.LongTensor)\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                output = model_resnet18(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.data.item() * inputs.size(0)\n",
    "            training_loss /= len(train_loader.dataset)\n",
    "            model_resnet18.eval()\n",
    "            print(\n",
    "                f\"Train-on-val epoch: {epoch}\"\n",
    "                f\", train_loss: {round(training_loss, 2)}\"\n",
    "            )\n",
    "\n",
    "        # save trained model to self\n",
    "        self.pytorch_model = model_resnet18\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_minority_class(image_paths, image_labels):\n",
    "        # TODO: remove funtion after implementing augmentation in preprocess\n",
    "\n",
    "        # init resut\n",
    "        image_paths_aug = []\n",
    "        image_labels_aug = []\n",
    "\n",
    "        # augment data\n",
    "        image_labels_counts = pd.Series(image_labels).value_counts().sort_values()\n",
    "        minority_class, majority_class = tuple(image_labels_counts.index)\n",
    "        class_count_diff = (\n",
    "            image_labels_counts[majority_class] - image_labels_counts[minority_class]\n",
    "        )\n",
    "        image_paths_new = (\n",
    "            pd.Series(image_paths[image_labels == minority_class])\n",
    "            .sample(class_count_diff, replace=True, random_state=42)\n",
    "            .to_list()\n",
    "        )\n",
    "        image_labels_new = [minority_class] * class_count_diff\n",
    "        image_paths_aug = image_paths + image_paths_new\n",
    "        image_labels_aug = image_labels + image_labels_new\n",
    "\n",
    "        # shuffle augmented data\n",
    "        image_paths_aug, image_labels_aug = zip(\n",
    "            *np.random.default_rng(seed=42).permutation(\n",
    "                list(zip(image_paths_aug, image_labels_aug))\n",
    "            )\n",
    "        )\n",
    "        image_paths_aug = [str(path) for path in image_paths_aug]\n",
    "        image_labels_aug = [float(label) for label in image_labels_aug]\n",
    "\n",
    "        return image_paths_aug, image_labels_aug\n",
    "\n",
    "    def predict(self, image_paths):\n",
    "\n",
    "        # init result\n",
    "        pred_labels = []\n",
    "\n",
    "        # get dataloader\n",
    "        dataloader = BigFlareFinder.preprocess(image_paths)\n",
    "\n",
    "        # make predictions\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(self.device)\n",
    "            output = self.pytorch_model(inputs)\n",
    "            predictions = torch.max(F.softmax(output, dim=1), dim=1)[1]\n",
    "            pred_labels.extend(predictions.cpu().numpy())\n",
    "\n",
    "        return pred_labels\n",
    "\n",
    "    def pred_proba(self, image_paths):\n",
    "\n",
    "        # init result\n",
    "        pred_probas = []\n",
    "\n",
    "        # get dataloader\n",
    "        dataloader = BigFlareFinder.preprocess(image_paths)\n",
    "\n",
    "        # make predictions\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(self.device)\n",
    "            output = self.pytorch_model(inputs)\n",
    "            predictions = F.softmax(output, dim=1)[:, 1]\n",
    "\n",
    "            # pdb.set_trace()\n",
    "\n",
    "            pred_probas.extend(predictions.detach().cpu().numpy().tolist())\n",
    "\n",
    "        return pred_probas\n",
    "\n",
    "    @staticmethod\n",
    "    def get_model_performance_metrics(y_true, y_pred):\n",
    "        metrics_dict = {\n",
    "            \"accuracy\": round(accuracy_score(y_true, y_pred), 2),\n",
    "            \"f1\": round(f1_score(y_true, y_pred), 2),\n",
    "            \"precision_class_1\": round(\n",
    "                precision_score(y_true, y_pred, zero_division=0), 2\n",
    "            ),\n",
    "            \"recall_class_1\": round(recall_score(y_true, y_pred, zero_division=0), 2),\n",
    "            \"actual_distru\": pd.Series(y_true).value_counts().sort_index().to_dict(),\n",
    "            \"pred_distru\": pd.Series(y_pred).value_counts().sort_index().to_dict(),\n",
    "        }\n",
    "        return metrics_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(image_paths, image_labels=None, augment_minority_class=False):\n",
    "        # TODO: add data augmentation option; see https://stackoverflow.com/questions/51677788/data-augmentation-in-pytorch\n",
    "\n",
    "        # make dataset of image_paths and image_labels\n",
    "        image_dimension = 224\n",
    "        image_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_dimension, image_dimension)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        image_labels = image_labels or [0] * len(image_paths)\n",
    "        dataset = CustomImageDataset(image_paths, image_labels, image_transforms)\n",
    "\n",
    "        # make dataloader for dataset\n",
    "        batch_size = 32\n",
    "        num_workers = 2\n",
    "        dataloader = DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "        )\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    @staticmethod\n",
    "    def split_into_train_test_by_time(image_paths, image_labels, test_frac):\n",
    "        # make images_df\n",
    "        images_df = pd.DataFrame(\n",
    "            {\"image_path\": image_paths, \"image_label\": image_labels}\n",
    "        )\n",
    "\n",
    "        # add a datetime column\n",
    "        images_df[\"datetime\"] = pd.to_datetime(\n",
    "            images_df[\"image_path\"].str.split(\"/\").str[-1].str[None:-4]\n",
    "        )\n",
    "\n",
    "        # sort images_df by datetime\n",
    "        images_df = images_df.sort_values(\"datetime\")\n",
    "\n",
    "        # find min and max datetimes of images_df\n",
    "        min_datetime = images_df[\"datetime\"].min()\n",
    "        max_datetime = images_df[\"datetime\"].max()\n",
    "\n",
    "        # find time span between min and max datetimes (in days)\n",
    "        time_span_in_days = (max_datetime - min_datetime).days\n",
    "\n",
    "        # get the two dfs by splitting the time span into the desired ratio\n",
    "        num_train_days = time_span_in_days * (1 - test_frac)\n",
    "        end_train_datetime = min_datetime + pd.to_timedelta(num_train_days, unit=\"days\")\n",
    "        train_df = images_df[images_df[\"datetime\"] <= end_train_datetime]\n",
    "        test_df = images_df[images_df[\"datetime\"] > end_train_datetime]\n",
    "\n",
    "        # get image_paths_train, image_paths_test, image_labels_train, image_labels_test\n",
    "        image_paths_train = train_df[\"image_path\"].to_list()\n",
    "        image_paths_test = test_df[\"image_path\"].to_list()\n",
    "        image_labels_train = train_df[\"image_label\"].to_list()\n",
    "        image_labels_test = test_df[\"image_label\"].to_list()\n",
    "\n",
    "        return (\n",
    "            image_paths_train,\n",
    "            image_paths_test,\n",
    "            image_labels_train,\n",
    "            image_labels_test,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fG-qjguPgSzV",
    "outputId": "a59f39ed-8ed8-4969-d435-a514871b542c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 253MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 0, train_loss: 0.28\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 1, train_loss: 0.08\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 2, train_loss: 0.05\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 3, train_loss: 0.03\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 4, train_loss: 0.04\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 5, train_loss: 0.03\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 6, train_loss: 0.03\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train-on-val epoch: 0, train_loss: 1.94\n",
      "Train-on-val epoch: 1, train_loss: 0.64\n",
      "Train-on-val epoch: 2, train_loss: 0.4\n",
      "Train-on-val epoch: 3, train_loss: 0.17\n",
      "Train-on-val epoch: 4, train_loss: 0.1\n",
      "Train-on-val epoch: 5, train_loss: 0.08\n",
      "Train-on-val epoch: 6, train_loss: 0.06\n",
      "\n",
      "image_pred_probas_test: [0.0019624338019639254, 0.0016745947068557143, 0.001745368936099112, 0.0014335069572553039, 0.0017774580046534538, 0.0017562604043632746, 0.0009841772262006998, 0.0013547337148338556, 0.0011991194915026426, 0.002234696177765727, 0.0032680381555110216, 0.0021217421162873507, 0.0011912515619769692, 0.0019378627184778452, 0.0013430562103167176, 0.003942640032619238, 0.004160708747804165, 0.0032639428973197937, 0.0031869325321167707, 0.0019026724621653557, 0.003235575510188937, 0.005234216805547476, 0.004911696072667837, 0.0021865186281502247, 0.005094759166240692, 0.004667007364332676, 0.0034682590048760176, 0.0031328219920396805, 0.002783962758257985, 0.006927069276571274, 0.006467481143772602, 0.008987785317003727, 0.005651263054460287, 0.00909392349421978, 0.012785715982317924, 0.01415221393108368, 0.013782946392893791, 0.012321271002292633, 0.03208013251423836, 0.026825765147805214, 0.024243244901299477, 0.027080973610281944, 0.02532750740647316, 0.01774495653808117, 0.011575648561120033, 0.016209380701184273, 0.013614090159535408, 0.0055237035267055035, 0.004598666913807392, 0.006685374304652214, 0.006145765073597431, 0.008249093778431416, 0.009250840172171593, 0.05753817781805992, 0.11732225865125656, 0.21296638250350952, 0.17760254442691803, 0.13487862050533295, 0.05107838660478592, 0.06928049027919769, 0.07030197232961655, 0.047622647136449814, 0.03217041492462158, 0.025203945115208626, 0.03575955331325531, 0.02205902524292469, 0.014914964325726032, 0.02494361624121666, 0.01839861087501049, 0.01858043484389782, 0.01697411946952343, 0.06058427318930626, 0.029017534106969833, 0.028736913576722145, 0.023986130952835083, 0.016040200367569923, 0.08058331906795502, 0.006161573808640242, 0.00427983608096838, 0.0695539191365242, 0.022036846727132797, 0.020961621776223183, 0.011340539902448654, 0.022297590970993042, 0.18502850830554962, 0.035379357635974884, 0.06500434130430222, 0.016704406589269638, 0.009303681552410126, 0.003718234598636627, 0.030463822185993195, 0.03436883166432381, 0.07418505847454071, 0.02851017750799656, 0.047083888202905655, 0.04301254823803902, 0.09324026852846146, 0.04381619393825531, 0.034306932240724564, 0.012340551242232323, 0.01758250780403614, 0.06696733087301254, 0.038411956280469894, 0.015740307047963142, 0.01800960674881935, 0.07517300546169281, 0.030908284708857536, 0.03241010755300522, 0.130489781498909, 0.11403413861989975, 0.03881026431918144, 0.048264067620038986, 0.03753860294818878, 0.5878403782844543, 0.4520401656627655, 0.39523303508758545, 0.14084456861019135, 0.021410400047898293, 0.3518029451370239, 0.005303889513015747, 0.005535765551030636, 0.0032764689531177282, 0.0035313561093062162, 0.003376214299350977, 0.027306020259857178, 0.01994321495294571, 0.006422449368983507, 0.015328715555369854, 0.003929000813513994, 0.0034576435573399067, 0.01642715185880661, 0.015585423447191715, 0.04128185659646988, 0.007999217137694359, 0.03782639279961586, 0.01703345775604248, 0.029042016714811325, 0.01653185300529003, 0.002640324179083109, 0.011735892854630947, 0.005820044316351414, 0.0019602561369538307, 0.0038139685057103634, 0.0009981727926060557, 0.0013712476938962936, 0.0007555297925136983, 0.001010375446639955, 0.0014068130403757095, 0.0011726649245247245, 0.0020349544938653708, 0.00529598630964756, 0.0034993737936019897, 0.0020111105404794216, 0.0010406214278191328, 0.0021647512912750244, 0.002887073205783963, 0.00468030059710145, 0.00482178246602416, 0.005074311513453722, 0.0035721464082598686, 0.007270655129104853, 0.003469145391136408, 0.00479391822591424, 0.0036033187061548233, 0.005804744083434343, 0.003704770701006055, 0.005818467121571302, 0.007126298733055592, 0.019689051434397697, 0.022088441997766495, 0.054067667573690414, 0.027426037937402725, 0.022872453555464745, 0.04398127272725105, 0.02088037319481373, 0.014022237621247768, 0.01139337569475174, 0.013888115994632244, 0.014598113484680653, 0.007132894825190306, 0.0055552138946950436, 0.011116220615804195, 0.007452470250427723, 0.00523097300902009, 0.0034780320711433887, 0.007046415004879236, 0.0057195196859538555, 0.0023215627297759056, 0.03043252043426037, 0.00802921038120985, 0.009786362759768963, 0.007192153949290514, 0.005308331921696663, 0.004264391027390957, 0.0077441842295229435, 0.003117919433861971, 0.004424742888659239, 0.005392978433519602, 0.003467770991846919, 0.0022616114001721144, 0.0009683338575996459, 0.0035217797849327326, 0.006069897208362818, 0.007975433021783829, 0.0014059559907764196, 0.005395531188696623, 0.0037985784001648426, 0.004476569127291441, 0.013582666404545307, 0.0067199901677668095, 0.007067967671900988, 0.008667917922139168, 0.019097521901130676, 0.012732414528727531, 0.008029475808143616, 0.013289466500282288, 0.003104201750829816, 0.01095935981720686, 0.005488878581672907, 0.008357596583664417]\n"
     ]
    }
   ],
   "source": [
    "# we want to test the pred_proba functionality\n",
    "# * we want to train the model and use it get prediction probabilites given an image as input\n",
    "\n",
    "# get the image data: image_paths, image_labels\n",
    "image_folder_path = f\"{path_to_coderepo}/../../data/sdo_images_w=131a\"\n",
    "big_flare_labels_df = pd.read_csv(f\"{image_folder_path}/big_flare_labels.csv\").dropna()\n",
    "\n",
    "# [TEMP] shorten big_flare_labels_df\n",
    "big_flare_labels_df = big_flare_labels_df.sort_values('solar_image_filename').iloc[None:500]\n",
    "\n",
    "image_paths = (\n",
    "    image_folder_path + \"/\" + big_flare_labels_df[\"solar_image_filename\"]\n",
    ").to_list()\n",
    "image_labels = big_flare_labels_df[\"is_big_flare\"].to_list()\n",
    "\n",
    "# split image_paths and image_labels by time:\n",
    "#     image_paths_train, image_paths_test, image_labels_train, image_labels_test\n",
    "test_frac = 0.5\n",
    "image_paths_train, image_paths_test, image_labels_train, image_labels_test = (\n",
    "    BigFlareFinder.split_into_train_test_by_time(image_paths, image_labels, test_frac)\n",
    ")\n",
    "\n",
    "# train model\n",
    "big_flare_finder = BigFlareFinder()\n",
    "model = big_flare_finder.fit(image_paths_train, image_labels_train)\n",
    "\n",
    "# get prediction probabilites\n",
    "image_pred_probas_test = big_flare_finder.pred_proba(image_paths_test)\n",
    "print(f\"\\nimage_pred_probas_test: {image_pred_probas_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75xX81fXWTVY",
    "outputId": "2fa3f2d3-19be-4d8c-f7cb-df1f811bf96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_probas_labels is equal to predict_labels\n"
     ]
    }
   ],
   "source": [
    "# compare pred_proba labels to pred labels\n",
    "# * we start with the fitted model big_flare_finder, and the test image_paths\n",
    "# * get the pred_proba labels and the predict labels\n",
    "\n",
    "pred_probas = big_flare_finder.pred_proba(image_paths_test)\n",
    "pred_probas_labels = [1 if pred_proba > 0.5 else 0 for pred_proba in pred_probas]\n",
    "predict_labels = big_flare_finder.predict(image_paths_test)\n",
    "\n",
    "# check if pred_probas_labels is equal to predict_labels\n",
    "if pred_probas_labels == predict_labels:\n",
    "    print(\"pred_probas_labels is equal to predict_labels\")\n",
    "else:\n",
    "    print(\"pred_probas_labels is not equal to predict_labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "pppMp5AitL2S",
    "outputId": "bde5a9d5-3d54-479a-fce6-8367bdde2786"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_paths_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5585a79b766f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_paths_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image_paths_test' is not defined"
     ]
    }
   ],
   "source": [
    "image_paths_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42BpT1U1e2Hb",
    "outputId": "0da6df37-e69b-4197-90ac-c33e2e83b0ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 0, train_loss: 0.28\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 1, train_loss: 0.08\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 2, train_loss: 0.05\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 3, train_loss: 0.03\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 4, train_loss: 0.04\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 5, train_loss: 0.03\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train epoch: 6, train_loss: 0.03\n",
      "val_metrics: {'accuracy': 0.98, 'f1': 0.0, 'precision_class_1': 0.0, 'recall_class_1': 0.0, 'actual_distru': {0.0: 136, 1.0: 3}, 'pred_distru': {0: 139}}\n",
      "Train-on-val epoch: 0, train_loss: 1.94\n",
      "Train-on-val epoch: 1, train_loss: 0.64\n",
      "Train-on-val epoch: 2, train_loss: 0.4\n",
      "Train-on-val epoch: 3, train_loss: 0.17\n",
      "Train-on-val epoch: 4, train_loss: 0.1\n",
      "Train-on-val epoch: 5, train_loss: 0.08\n",
      "Train-on-val epoch: 6, train_loss: 0.06\n",
      "\n",
      "test_metrics: {'accuracy': 0.97, 'f1': 0.25, 'precision_class_1': 1.0, 'recall_class_1': 0.14, 'actual_distru': {0.0: 213, 1.0: 7}, 'pred_distru': {0: 219, 1: 1}}\n"
     ]
    }
   ],
   "source": [
    "# get predict() performance of model on test data\n",
    "\n",
    "# get the image data: image_paths, image_labels\n",
    "image_folder_path = f\"{path_to_coderepo}/../../data/sdo_images_w=131a\"\n",
    "big_flare_labels_df = pd.read_csv(f\"{image_folder_path}/big_flare_labels.csv\").dropna()\n",
    "\n",
    "# [TEMP] shorten big_flare_labels_df\n",
    "big_flare_labels_df = big_flare_labels_df.sort_values('solar_image_filename').iloc[None:500]\n",
    "\n",
    "image_paths = (\n",
    "    image_folder_path + \"/\" + big_flare_labels_df[\"solar_image_filename\"]\n",
    ").to_list()\n",
    "image_labels = big_flare_labels_df[\"is_big_flare\"].to_list()\n",
    "\n",
    "# split image_paths and image_labels by time:\n",
    "#     image_paths_train, image_paths_test, image_labels_train, image_labels_test\n",
    "test_frac = 0.5\n",
    "image_paths_train, image_paths_test, image_labels_train, image_labels_test = (\n",
    "    BigFlareFinder.split_into_train_test_by_time(image_paths, image_labels, test_frac)\n",
    ")\n",
    "\n",
    "# train model\n",
    "big_flare_finder = BigFlareFinder()\n",
    "model = big_flare_finder.fit(image_paths_train, image_labels_train)\n",
    "\n",
    "# make predictions\n",
    "image_labels_test_pred = big_flare_finder.predict(image_paths_test)\n",
    "\n",
    "# get pred metrics\n",
    "test_metrics = BigFlareFinder.get_model_performance_metrics(image_labels_test, image_labels_test_pred)\n",
    "print(f\"\\ntest_metrics: {test_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "1S4VKMRHzNH1",
    "outputId": "833e1962-0d6f-4810-c3f6-f9cb645ca825"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of big flares as a function of month\n",
    "\n",
    "# set the style of plotting to seaborn whitegrid\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# get the image data: image_paths, image_labels\n",
    "image_folder_path = f\"{path_to_coderepo}/../../data/sdo_images_w=131a\"\n",
    "big_flare_labels_df = pd.read_csv(f\"{image_folder_path}/big_flare_labels.csv\").dropna().sort_values('solar_image_filename')\n",
    "\n",
    "# get datetime from solar_image_filename in big_flare_labels_df\n",
    "big_flare_labels_df['datetime'] = pd.to_datetime(big_flare_labels_df['solar_image_filename'].str.split('.').str[0], errors = 'coerce')\n",
    "\n",
    "# bin datetime to first day of month\n",
    "big_flare_labels_df['date_bin'] = big_flare_labels_df['datetime'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# groupby date_bin and sum is_big_flare\n",
    "# rotate the x axis labels\n",
    "ax = big_flare_labels_df.groupby('date_bin')['is_big_flare'].sum().plot(kind='bar')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "_ = ax.set_xticklabels([label.get_text()[:10] for label in ax.get_xticklabels()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkG1Mrg-WxF6"
   },
   "outputs": [],
   "source": [
    "# modify pred to output probabilities and rename it is predict_proba\n",
    "# test on the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dunZPQke0MXB"
   },
   "outputs": [],
   "source": [
    "# train big-flare classifier\n",
    "# * train big-flare classifier on first 70% of 2015 and test on last 30%\n",
    "# * show prediction-quality (accuracy, f1, precn, recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAmWCvgkS7je"
   },
   "outputs": [],
   "source": [
    "# show the timeline of flares in test along with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yntWKplVS9qk"
   },
   "outputs": [],
   "source": [
    "# show what the model learned\n",
    "# * some viz of features picked up by the model for big-flares"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
