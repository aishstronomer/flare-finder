{"cells":[{"cell_type":"markdown","id":"C1QdNWGH30ga","metadata":{"id":"C1QdNWGH30ga"},"source":["# SDO Machine Learning (SDO ML) Dataset\n","\n","In this notebook we demonstrate the process for interacting with a small sample of the SDO ML dataset."]},{"cell_type":"markdown","id":"3Dsap7YC30ge","metadata":{"id":"3Dsap7YC30ge"},"source":["*Meng Jin, Mark Cheung, & Paul Wright*"]},{"cell_type":"markdown","id":"vTNRN73m30ge","metadata":{"id":"vTNRN73m30ge"},"source":["---"]},{"cell_type":"markdown","id":"QzPKmLuL30gf","metadata":{"id":"QzPKmLuL30gf"},"source":["## Introduction"]},{"cell_type":"markdown","id":"CwkB_JVc30gf","metadata":{"id":"CwkB_JVc30gf"},"source":["### SDO Overview\n","\n","Since its launch in 2010, NASA’s Solar Dynamics Observatory (SDO; ([Pesnell et al. 2012](https://ui.adsabs.harvard.edu/abs/2012SoPh..275....3P/abstract)) has continuously monitored Sun's activity, delivering a wealth of valuable scientific data for heliophysics researchers with the use of three instruments:\n","\n","1. The Atmospheric Imaging Assembly (AIA; [Lemen et al. 2012](https://ui.adsabs.harvard.edu/abs/2012SoPh..275...17L/abstract)), which captures 4096 x 4096 resolution images (with 0.6 arcsecond pixel size) of the full Sun in two ultraviolet (centered at 1600, and 1700 Å), seven extreme ultraviolet (EUV; centered at 94, 131, 171, 193, 211, 304, and 335 Å), and one visible (centered at 4500 Å) wavelength band.\n","\n","\n","2. The Helioseismic and Magnetic Imager (HMI; [Schou et al. 2012](https://ui.adsabs.harvard.edu/abs/2012SoPh..275..229S/abstract)) captures visible wavelength filtergrams of the full Sun at 4096 x 4096 resolution (a pixel size of 0.5 arcsecond), which are then processed into a number of data products, including photospheric Dopplergrams, line-of-sight magnetograms, and vector magnetograms ([Hoeksema et al. 2014](https://ui.adsabs.harvard.edu/abs/2014SoPh..289.3483H/abstract)).\n","\n","\n","3. The EUV Variability Experiment (EVE; [Woods et al. 2012](https://ui.adsabs.harvard.edu/abs/2012SoPh..275..115W/abstract)) monitors the solar EUV spectral irradiance from 1 to 1050 Å. This is done by utilizing multiple EUV Grating Spectrographs (MEGS) that disperse EUV light from the full disk of the Sun and its corona onto a 1024 x 2048 charge coupled device (CCD)."]},{"cell_type":"markdown","id":"_dfn2Phj30gg","metadata":{"id":"_dfn2Phj30gg"},"source":["<img src=\"https://github.com/spaceml-org/helionb-sdoml/blob/main/notebooks/01_sdoml_dataset_2018/spacecraft_detailed.png?raw=1\" width=\"400\">"]},{"cell_type":"markdown","id":"lrntSIJc30gh","metadata":{"id":"lrntSIJc30gh"},"source":["**Figure 1:** The Solar Dynamics Observatory (SDO) spacecraft, shown with the three main instruments (AIA, EVE, and HMI) highlighted. Image courtesy of NASA (https://sdo.gsfc.nasa.gov)."]},{"cell_type":"markdown","id":"Dhwls7SV30gh","metadata":{"id":"Dhwls7SV30gh"},"source":["### The SDO ML Dataset\n","The SDO ML Dataset (covering 2010 - 2018) was originally published as [Galvez et al (2019)](https://ui.adsabs.harvard.edu/abs/2019ApJS..242....7G/abstract), and is hosted on the Stanford Digital Repository in Numpy's compressed array format (.npz).\n","\n","In this notebook, we present an update to the work outlined in Galvez et al (2019), in which the full dataset has been converted to cloud friendly Zarr format. Specifically, SDO/AIA data has been updated to account for a change in calibration after 2019. In addtion to the change in calibration, this updated format includes:\n","\n","1. FITS header/keyword information (such as observation time, and exposure time).\n","\n","2. processes for continually updating the data until the present day."]},{"cell_type":"markdown","id":"ueZYQ4zh30gi","metadata":{"id":"ueZYQ4zh30gi"},"source":["### Who is the SDO ML Dataset for?\n","\n","The sheer volume of structured scientific data recorded by SDO (over 18 PB, and counting) is ideal for a range machine learning tasks (from time-series, to computer vision), as well as more traditional approaches.\n","\n","While the level 1 data are easily accessible, pre-processing these data for scientific analysis often requires  specialized heliophysics (and instrument-specific) knowledge. This may act as an unnecessary hurdle for non-heliophysics machine learning researchers who may wish to experiment with datasets from the physical sciences, but are unaware of domain-specific nuances (e.g., that images must be spatially and temporally adjusted).\n","\n","This notebook demonstrates the process for interacting with a subset of the curated SDO (AIA, HMI, EVE) dataset, that is mission-ready for machine-learning applications. **Our aim is to supply this standardized dataset for heliophysicists who wish to use machine learning in their own research, as well as machine-learning researchers who wish to develop models specialized for the physical sciences.**"]},{"cell_type":"markdown","id":"mPr9KxH530gj","metadata":{"id":"mPr9KxH530gj"},"source":["---"]},{"cell_type":"markdown","id":"wN12n26Q30gj","metadata":{"id":"wN12n26Q30gj"},"source":["## Table of Contents"]},{"cell_type":"markdown","id":"UQqgdYtr30gk","metadata":{"id":"UQqgdYtr30gk"},"source":["The notebook is set out as follows:\n","\n","1. Setting up the notebook\n","2. Reading and loading the data <br>\n","2a. Selecting images based on header information <br>\n","    2b. Selecting a subset of the data based on index <br>\n","    2c. Downsampling the data (resolution)<br>\n","    2d. Downsampling the data (temporally)<br>\n","3. Generating a SunPy map\n","4. Animating AIA data\n","5. Reading and loading HMI data\n","6. Reading and loading EVE data"]},{"cell_type":"markdown","id":"06e3u0qQ30gk","metadata":{"id":"06e3u0qQ30gk"},"source":["## 1. Setting up the notebook"]},{"cell_type":"code","execution_count":null,"id":"5930c3e4","metadata":{},"outputs":[],"source":["# use this pip install command to install all the necessary packages in your conda environment\n","#pip install zarr \"sunpy[all]\" s3fs"]},{"cell_type":"code","execution_count":1,"id":"jaFbHF6Z30gq","metadata":{"executionInfo":{"elapsed":10626,"status":"ok","timestamp":1703180810715,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"jaFbHF6Z30gq"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/aishsk6/anaconda3/envs/mlproject/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# %matplotlib inline\n","\n","import os\n","from typing import Union\n","import zarr\n","\n","# import gcsfs\n","import s3fs\n","import sunpy.map\n","\n","import dask.array as da\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import pandas as pd\n","import sunpy.visualization.colormaps as cm\n","\n","from astropy.time import Time\n","from sunpy.visualization import axis_labels_from_ctype, wcsaxes_compat\n","\n","from matplotlib import animation\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":2,"id":"XQGn2v6_30gr","metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1703180880946,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"XQGn2v6_30gr"},"outputs":[],"source":["# AWS_ZARR_ROOT = (\n","#     \"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2_small.zarr/\"\n","# )\n","\n","AWS_ZARR_ROOT = (\n","    \"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2.zarr/2015/\"\n",")\n","\n","\n","\n","def s3_connection(path_to_zarr: os.path) -> s3fs.S3Map:\n","    \"\"\"\n","    Instantiate connection to aws for a given path `path_to_zarr`\n","    \"\"\"\n","    return s3fs.S3Map(\n","        root=path_to_zarr,\n","        s3=s3fs.S3FileSystem(anon=True),\n","        # anonymous access requires no credentials\n","        check=False,\n","    )\n","\n","\n","def load_single_aws_zarr(\n","    path_to_zarr: os.path,\n","    cache_max_single_size: int = None,\n",") -> Union[zarr.Array, zarr.Group]:\n","    \"\"\"\n","    load zarr from s3 using LRU cache\n","    \"\"\"\n","    return zarr.open(\n","        zarr.LRUStoreCache(\n","            store=s3_connection(path_to_zarr),\n","            max_size=cache_max_single_size,\n","        ),\n","        mode=\"r\",\n","    )"]},{"cell_type":"markdown","id":"pHCnRpFi30gr","metadata":{"id":"pHCnRpFi30gr"},"source":["## 2. Reading and loading the AIA data\n"]},{"cell_type":"markdown","id":"u8yLRK4x30gr","metadata":{"id":"u8yLRK4x30gr"},"source":["The SDO ML dataset is stored in the Zarr format, a format for the storage of chunked, compressed, N-dimensional arrays with Numpy dtype. For an in-depth overview, see https://zarr.readthedocs.io/en/stable/tutorial.html."]},{"cell_type":"code","execution_count":3,"id":"IaWjptjK30gr","metadata":{"executionInfo":{"elapsed":1375,"status":"ok","timestamp":1703180885235,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"IaWjptjK30gr"},"outputs":[],"source":["# first, we create a group with the store data located on GCP.\n","root = load_single_aws_zarr(\n","    path_to_zarr=AWS_ZARR_ROOT,\n",")"]},{"cell_type":"code","execution_count":4,"id":"L5sUBFP-30gs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29107,"status":"ok","timestamp":1703180914336,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"L5sUBFP-30gs","outputId":"c7878077-e488-4284-93a3-b6569e74b7cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/\n"," ├── 131A (82822, 512, 512) float32\n"," ├── 1600A (82859, 512, 512) float32\n"," ├── 1700A (74863, 512, 512) float32\n"," ├── 171A (82806, 512, 512) float32\n"," ├── 193A (82849, 512, 512) float32\n"," ├── 211A (82842, 512, 512) float32\n"," ├── 304A (82845, 512, 512) float32\n"," ├── 335A (82834, 512, 512) float32\n"," └── 94A (82870, 512, 512) float32\n"]}],"source":["# Using `root.tree()`, we are able to display the hierarchy (of `loc`).\n","print(root.tree())"]},{"cell_type":"markdown","id":"4rkpT-1q30gs","metadata":{"id":"4rkpT-1q30gs"},"source":["As shown in the tree, the heirachy consists of groups, each shown with their respective shape, and data type. In this example, we will primarily look at the 171 Å channel from 2010. This consists of 6135 512x512 images, stored as float32, and can be accessed as follows:"]},{"cell_type":"code","execution_count":5,"id":"AEKhkUv330gt","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703180914336,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"AEKhkUv330gt"},"outputs":[],"source":["data = root[\"171A\"]"]},{"cell_type":"markdown","id":"CP-3yVdt30gt","metadata":{"id":"CP-3yVdt30gt"},"source":["We could have alternatively accessed the 2010 data as:\n","\n","```\n","loc = 'fdl-sdoml-v2/sdomlv2_small.zarr/2010'\n","```\n","\n","which becomes increasingly useful in the full dataset (where the heirachy contains years 2010 - present)."]},{"cell_type":"markdown","id":"GOq4PfFF30gt","metadata":{"id":"GOq4PfFF30gt"},"source":["**Loading with Dask**\n","\n","We can then load this data into an array using dask."]},{"cell_type":"code","execution_count":null,"id":"uw-tZXju30gt","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1703180958378,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"uw-tZXju30gt","outputId":"f13b3d53-9363-43b0-8105-c6cc44ac701e"},"outputs":[],"source":["all_image = da.from_array(data)\n","all_image"]},{"cell_type":"markdown","id":"39fny1di30gt","metadata":{"id":"39fny1di30gt"},"source":["As shown above, the data has the shape (6135, 512, 512), and is split into 52 chunks of (120, 512, 512), each of 125.83 MB; this is further visualised on the right. The data is now in a form to be manipulated like a Numpy array.\n","\n","We can load and display one image now:"]},{"cell_type":"code","execution_count":null,"id":"d8d03557","metadata":{},"outputs":[],"source":["image=all_image[15557,:,:]\n","plt.figure(figsize=(10,10))\n","colormap = plt.get_cmap('sdoaia171')\n","plt.imshow(image,origin='lower',vmin=10,vmax=1000,cmap=colormap)"]},{"cell_type":"markdown","id":"nfMrsRiQ30gu","metadata":{"id":"nfMrsRiQ30gu"},"source":["Depending on the use-case, we may wish to extract a subset of this data in various ways. In the following sections we step through a number of potential operations that we may wish to make with the data."]},{"cell_type":"markdown","id":"9NCHr5-930gu","metadata":{"id":"9NCHr5-930gu"},"source":["### 2a. Selecting images based on header information"]},{"cell_type":"markdown","id":"gLRnFQv930gu","metadata":{"id":"gLRnFQv930gu"},"source":["The new data includes all fits header information with the same keywords. To find out the AIA keyword definition, one can refer to the following online document:\n","http://jsoc.stanford.edu/~jsoc/keywords/AIA/AIA02840_K_AIA-SDO_FITS_Keyword_Document.pdf\n","\n","And one can list all the AIA keywords included:"]},{"cell_type":"code","execution_count":null,"id":"Mi9WkhZr30gu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13329,"status":"ok","timestamp":1703180987623,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"Mi9WkhZr30gu","outputId":"ce978be2-689c-4ad3-94d7-f311714b8402"},"outputs":[],"source":["sorted(data.attrs)"]},{"cell_type":"markdown","id":"pCxxPVNz30gu","metadata":{"id":"pCxxPVNz30gu"},"source":["We can extract the exposure (and observation) time from the data attributes (the header information), and downsample our data based upon that information."]},{"cell_type":"code","execution_count":null,"id":"4bgxwZZv30gu","metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1703180991304,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"4bgxwZZv30gu"},"outputs":[],"source":["exptime = np.array(data.attrs[\"EXPTIME\"])\n","t_obs = np.array(data.attrs[\"T_OBS\"])"]},{"cell_type":"code","execution_count":null,"id":"UK7mewfd30gv","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"elapsed":769,"status":"ok","timestamp":1703180993145,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"UK7mewfd30gv","outputId":"4f87234f-f317-4fcb-b7bb-23c58bd26cf7"},"outputs":[],"source":["plt.plot(exptime)"]},{"cell_type":"code","execution_count":null,"id":"nR_5YZGV6NiR","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1703180995809,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"nR_5YZGV6NiR","outputId":"7dc2266d-00d2-4b58-ef2d-e2e0dd1a3bb6"},"outputs":[],"source":["t_obs"]},{"cell_type":"code","execution_count":null,"id":"GCgkSO8j30gv","metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1703181004352,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"GCgkSO8j30gv"},"outputs":[],"source":["# select indices where the exposure time is less than 2 seconds\n","index = np.where(exptime < 2.0)\n","selected_images = da.from_array(data)[index[0], :, :]"]},{"cell_type":"code","execution_count":null,"id":"1f5JmUaN30gv","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1703181009841,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"1f5JmUaN30gv","outputId":"e13deaba-21f5-4541-ba70-a5d2f670f075"},"outputs":[],"source":["selected_images"]},{"cell_type":"markdown","id":"p8nxNvye30gv","metadata":{"id":"p8nxNvye30gv"},"source":["### 2b. Selecting images based on indices"]},{"cell_type":"markdown","id":"Xf5x4ocU30gv","metadata":{"id":"Xf5x4ocU30gv"},"source":["While the data is not currently ordered by observation time, we can simple index the array to extract a number of observations"]},{"cell_type":"code","execution_count":null,"id":"aG9u9fol30gv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4404,"status":"ok","timestamp":1703181019300,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"aG9u9fol30gv","outputId":"7ad121c4-b749-4297-baf9-775c3615fbff"},"outputs":[],"source":["# select a subset of the data based on index\n","selected_images = da.from_array(data)[100:200, :, :]\n","selected_header = {keys: values[100:200] for keys, values in data.attrs.items()}\n","\n","# and even compute the mean of the selected images\n","print(f\"mean of selected images: {da.mean(selected_images).compute():.2f}\")"]},{"cell_type":"code","execution_count":null,"id":"6VePACQK30gw","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1703178746710,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"6VePACQK30gw","outputId":"18bb392d-e996-45eb-ff91-c9c095fda7d3"},"outputs":[],"source":["selected_images"]},{"cell_type":"code","execution_count":null,"id":"6kOskhiHaIgF","metadata":{"executionInfo":{"elapsed":184,"status":"ok","timestamp":1703181025489,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"6kOskhiHaIgF"},"outputs":[],"source":["# We are going to choose data in 1 hour intervals\n","\n","df_time = pd.DataFrame(t_obs, index=np.arange(np.shape(t_obs)[0]), columns=[\"Time\"])\n","df_time[\"Time\"] = pd.to_datetime(df_time[\"Time\"])\n","\n","# select times at a frequency of 60 minutes\n","selected_times = pd.date_range(\n","    start=\"2015-01-01 00:00:00\", end=\"2015-12-31 23:59:59\", freq=\"60T\", tz=\"UTC\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"mMznuOLAaUha","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"elapsed":27695,"status":"ok","timestamp":1703181057609,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"mMznuOLAaUha","outputId":"79a476cf-6d0c-4afb-9d36-1572b04bea48"},"outputs":[],"source":["# selected_index is finding all the dates available in df_time['Time'] which is\n","# in the actual data and the hourly time_index that I've created in selected_times\n","\n","selected_index = []\n","for i in selected_times[None:None]:\n","  # print(i)\n","  selected_index.append(np.argmin(abs(df_time[\"Time\"] - i)))\n","# may be a more efficient way of doing this\n","print('selected_index is: ', selected_index)\n","\n","# keep only elements in selected_index that are greater than zero - but why?\n","time_index = list(filter(lambda x: x > 0, selected_index))\n","print('time_index is: ', time_index)\n","\n","da.from_array(data)[time_index, :, :]"]},{"cell_type":"code","execution_count":null,"id":"7353f0e1","metadata":{},"outputs":[],"source":["df_time[\"Time\"][time_index]"]},{"cell_type":"markdown","id":"_dSPjfYe30gw","metadata":{"id":"_dSPjfYe30gw"},"source":["### 2c. Downsampling the data (resolution)"]},{"cell_type":"markdown","id":"LlYoMytG30gw","metadata":{"id":"LlYoMytG30gw"},"source":["Downsample the 512x512 images to 256x256"]},{"cell_type":"code","execution_count":null,"id":"JsAQmXV5cFrj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1703181057613,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"JsAQmXV5cFrj","outputId":"22731b3b-1490-4181-c82c-d46f8db5f8e3"},"outputs":[],"source":["time_index[0]"]},{"cell_type":"code","execution_count":null,"id":"9JUtmwTn30gw","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1703181141337,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"9JUtmwTn30gw","outputId":"c218f488-536a-4026-c1a5-f1beb6042fcf"},"outputs":[],"source":["# after selecting images via time_index, we wan to downsample in resolution\n","# For that we will relpace 0:600 in\n","# sub_image = da.from_array(data)[0:600, sub_index, :] with 'time_index'\n","\n","# downsample the data to 256 by sampling every other pixel\n","sub_index = np.arange(0, 512, 2)\n","\n","sub_image = da.from_array(data)[time_index, :, :]\n","sub_image = sub_image[:, sub_index, :]\n","sub_image = sub_image[:, :, sub_index]\n","sub_image\n","# # is this becuase dask doesn't support nd fancy indexing?\n","\n","# print(f\"mean of selected images: {da.mean(sub_image).compute():.2f}\")"]},{"cell_type":"code","execution_count":null,"id":"02b56af4","metadata":{},"outputs":[],"source":["sub_image_eg = sub_image[0,:,:]\n","plt.figure(figsize=(10,10))\n","colormap = plt.get_cmap('sdoaia171')\n","plt.imshow(sub_image_eg,origin='lower',vmin=10,vmax=1000,cmap=colormap)"]},{"cell_type":"code","execution_count":null,"id":"3e3917a7","metadata":{},"outputs":[],"source":["sub_image"]},{"cell_type":"code","execution_count":null,"id":"755e2cf6","metadata":{},"outputs":[],"source":["import pandas as pd\n","import json\n","\n","\n","images_df = pd.DataFrame(columns=[\"datetime\", \"image_pixels_nparrayjson\"])\n","\n","# Correct the loop to serialize each image's pixels\n","for image_num in list(range(len(time_index)))[None:None]:  # Simplified range if iterating over the first 10 images\n","    datetime_value = df_time[\"Time\"][time_index].values[image_num]\n","    image_pixels_nparrayjson = json.dumps(sub_image[image_num, :, :].compute().tolist())\n","    \n","    images_df = images_df._append({\n","        \"datetime\": datetime_value,\n","        \"image_pixels_nparrayjson\": image_pixels_nparrayjson\n","    }, ignore_index=True)\n","\n","images_df.head()"]},{"cell_type":"code","execution_count":null,"id":"3d7e7315","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"68WH74uMgjhT","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"elapsed":1983,"status":"ok","timestamp":1703189586623,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"68WH74uMgjhT","outputId":"fabde9de-58d3-4600-c7b4-2375c6919be9"},"outputs":[],"source":["import pandas as pd\n","# from google.colab import drive\n","\n","# drive.mount('/content/drive')\n","goes_events_2015 = pd.read_csv('/Users/aishwarya/gd/ML_project/code_repo/flare-finder/goes_events_clean_2015.csv')\n","goes_events_2015.head(10)"]},{"cell_type":"code","execution_count":null,"id":"c0127bce","metadata":{},"outputs":[],"source":["type(images_df['datetime'][0])"]},{"cell_type":"code","execution_count":null,"id":"e27b0173","metadata":{},"outputs":[],"source":["goes_events_2015['max_datetime'] = pd.to_datetime(goes_events_2015['max_datetime'], errors='coerce')\n","\n","# Update the function to match only with max_datetime and handle NaN appropriately\n","def find_match_with_max_datetime(image_datetime, threshold=pd.Timedelta(hours=1)):  # Adjust the threshold as needed\n","    # Filter out rows where max_datetime is NaN\n","    valid_events = goes_events_2015.dropna(subset=['max_datetime'])\n","    \n","    if valid_events.empty:\n","        return np.nan  # Return NaN if no valid max_datetime exists\n","\n","    # Calculate time differences only for valid max_datetime values\n","    time_diffs = valid_events['max_datetime'].apply(lambda x: abs(x - image_datetime))\n","    \n","    min_diff = time_diffs.min()  # Find the minimum time difference\n","    if min_diff <= threshold:\n","        return 1  # Match found within threshold\n","    else:\n","        return 0  # No match found within threshold\n","\n","# Apply the updated function to each datetime in images_df\n","images_df['flare_flag'] = images_df['datetime'].apply(find_match_with_max_datetime)\n","\n","images_df"]},{"cell_type":"code","execution_count":null,"id":"fac9a276","metadata":{},"outputs":[],"source":["#count number of 1s in flare_flag\n","images_df['flare_flag'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"9w2i5VHBk7n3","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1703189088013,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"9w2i5VHBk7n3","outputId":"d5c485e7-2343-49c7-c9e1-eebf5c94c6f4"},"outputs":[],"source":["images_df"]},{"cell_type":"code","execution_count":null,"id":"U6qpvo2L51qB","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1703189124005,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"U6qpvo2L51qB","outputId":"fae3f43a-2e76-4397-cd6a-3e6f76dd7736"},"outputs":[],"source":["np.shape(np.array(json.loads(images_df['image_pixels_np_str'][0])))"]},{"cell_type":"code","execution_count":null,"id":"gy1FON_g6OBR","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"elapsed":229,"status":"error","timestamp":1703188705167,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"gy1FON_g6OBR","outputId":"56b5249b-df81-4bdf-92e5-6428e27e5d7a"},"outputs":[],"source":["# Create a 2D NumPy array\n","array = np.array([[1, 2], [3, 4]])\n","\n","# Convert the array to a string\n","string = np.array_str(array)\n","print(string)\n","# Convert the string back to an array\n","new_array = np.fromstring(string)\n","\n","# Print the original array and the new array\n","print(array)\n","print(new_array)"]},{"cell_type":"code","execution_count":null,"id":"924EdV2TlKkj","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":307,"status":"error","timestamp":1703187788987,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"924EdV2TlKkj","outputId":"3ede70e6-be2f-48d4-84e2-c880d5370d04"},"outputs":[],"source":["np.fromstring(images_df['image_pixels_np_str'][0])"]},{"cell_type":"markdown","id":"6oLPymD_30gw","metadata":{"id":"6oLPymD_30gw"},"source":["### 2d. Downsampling the data (temporally)"]},{"cell_type":"markdown","id":"Rt7HPIPV30gx","metadata":{"id":"Rt7HPIPV30gx"},"source":["We can use pandas to downstample the data within a time-range. Here, we choose 1 day of observations at 12 minute frequency"]},{"cell_type":"code","execution_count":null,"id":"NclTghf2hNvb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"NclTghf2hNvb","outputId":"f4677425-1bb3-42c0-9be7-eaa68323e633"},"outputs":[],"source":["sub_image"]},{"cell_type":"code","execution_count":null,"id":"szM-eUrk30gx","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"szM-eUrk30gx","outputId":"f582fe21-552c-4af0-f09c-cece7802b06a"},"outputs":[],"source":["# selected_index is finding all the dates available in df_time['Time'] which is\n","# in the actual data and the hourly time_index that I've created in selected_times\n","\n","selected_index = []\n","for i in selected_times[None:None]:\n","  # print(i)\n","  selected_index.append(np.argmin(abs(df_time[\"Time\"] - i)))\n","# may be a more efficient way of doing this\n","print('selected_index is: ', selected_index)\n","\n","# keep only elements in selected_index that are greater than zero - but why?\n","time_index = list(filter(lambda x: x > 0, selected_index))\n","print('time_index is: ', time_index)\n","\n","da.from_array(data)[time_index, :, :]"]},{"cell_type":"markdown","id":"I-DT3Hrj30gx","metadata":{"id":"I-DT3Hrj30gx"},"source":["## 3. Generating a SunPy Map"]},{"cell_type":"markdown","id":"qmh6Io_730gx","metadata":{"id":"qmh6Io_730gx"},"source":["SunPy is an open-source Python library for Solar Physics data analysis and visualization.\n","\n","In this section we will demonstrate how SunPy’s [Map](https://docs.sunpy.org/en/stable/api/sunpy.map.Map.html#sunpy.map.Map) with the Zarr-formatted data. We demonstrate this for a single index."]},{"cell_type":"code","execution_count":null,"id":"TBLb2zv0S8gj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBLb2zv0S8gj","outputId":"29da738f-3794-4e18-e49c-1e58363a126f"},"outputs":[],"source":["#lets try to get the dates associated with time_index\n","df_time[\"Time\"][time_index]"]},{"cell_type":"code","execution_count":null,"id":"CLSbUjXC30gx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLSbUjXC30gx","outputId":"f9bf4006-d9e5-4693-8295-e5d4576c298a"},"outputs":[],"source":["# specify an image index -\n","# using the last time index\n","img_index = time_index[-2]\n","print(img_index)"]},{"cell_type":"code","execution_count":null,"id":"Gaj_LVsW30gx","metadata":{"id":"Gaj_LVsW30gx"},"outputs":[],"source":["# select the respective image, and header required for sunpy.map.Map()\n","selected_image = da.from_array(data)[img_index, :, :]\n","selected_headr = {keys: values[img_index] for keys, values in data.attrs.items()}"]},{"cell_type":"code","execution_count":null,"id":"JmlZoUmPkFJd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JmlZoUmPkFJd","outputId":"8e330e5d-a9dc-46c8-d408-66e6b5c9bbc3"},"outputs":[],"source":["type(data)"]},{"cell_type":"code","execution_count":null,"id":"X28jmtbg30gx","metadata":{"id":"X28jmtbg30gx"},"outputs":[],"source":["my_map = sunpy.map.Map((np.array(selected_image), selected_headr))"]},{"cell_type":"code","execution_count":null,"id":"YWpfJrQr30gy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"id":"YWpfJrQr30gy","outputId":"044c988f-81fe-4233-ff25-280ba5de80b0"},"outputs":[],"source":["plt.figure(figsize=(7, 7))\n","ax = plt.subplot(projection=my_map)\n","my_map.plot()"]},{"cell_type":"markdown","id":"Mtc9Z9kz30gy","metadata":{"id":"Mtc9Z9kz30gy"},"source":["As this is then a SunPy Map object, we can manipulate it as such."]},{"cell_type":"code","execution_count":null,"id":"3qw7pUhL30gy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"id":"3qw7pUhL30gy","outputId":"5dc71cd9-0581-4cb7-8f48-e4d73898a381"},"outputs":[],"source":["my_map"]},{"cell_type":"markdown","id":"ygreYJqx30gy","metadata":{"id":"ygreYJqx30gy"},"source":["For more information about SunPy, and Map, see the SunPy project: https://readthedocs.org/projects/sunpy/"]},{"cell_type":"markdown","id":"dvlyGtJH30gy","metadata":{"id":"dvlyGtJH30gy"},"source":["## 4. Generating an AIA animation"]},{"cell_type":"code","execution_count":null,"id":"BzDlpSNm30gy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"BzDlpSNm30gy","outputId":"f0125a18-bcf3-482c-fe9e-928f3a4dec94"},"outputs":[],"source":["maps = []\n","\n","for i in time_index:\n","    selected_image = da.from_array(data)[i, :, :]\n","    selected_headr = {keys: values[i] for keys, values in data.attrs.items()}\n","    maps.append(sunpy.map.Map((np.array(selected_image), selected_headr)))\n","\n","sq = sunpy.map.Map(maps, sequence=True, sortby=\"date\")"]},{"cell_type":"code","execution_count":null,"id":"Rfo9od9W30gz","metadata":{"id":"Rfo9od9W30gz"},"outputs":[],"source":["def animate_sequence(sequence, vmin = None, vmax = None):\n","    \"\"\"\n","    An animation plotting routine to animate each element in MapSequence\n","\n","    Parameters\n","    ----------\n","    sequence : `sunpy.map.mapsequence.MapSequence`\n","        a set of sunpy maps to animate\n","\n","    Returns\n","    -------\n","    `matplotlib.animation.FuncAnimation`\n","        A FuncAnimation instance.\n","    \"\"\"\n","\n","    # fig, ax = plt.subplots(figsize=(7,7),\n","    #                       subplot_kw=dict(projection=sequence[0].wcs)\n","    #                      )\n","\n","    ax = wcsaxes_compat.gca_wcs(sequence[0].wcs)\n","    fig = ax.get_figure()\n","    fig.figsize = (7, 7)\n","\n","    plot_obj = sequence[0].plot(vmin = vmin, vmax = vmax)\n","    ax.set_title(sequence[0].latex_name)\n","\n","    cbar = plt.colorbar()\n","\n","    def update_fig(i):\n","        ax.set_title(sequence[i].latex_name)\n","\n","        # set the data to that of the image being plot\n","        # Each image should be scaled as the first.\n","        plot_obj.set_data(sequence[i].data)\n","\n","        # reset the WCS to that of the image being plot\n","        plot_obj.axes.reset_wcs(sequence[i].wcs)\n","\n","        wcsaxes_compat.default_wcs_grid(ax)\n","        ax.set_xlabel(\n","            axis_labels_from_ctype(\n","                sequence[i].coordinate_system[0], sequence[i].spatial_units[0]\n","            )\n","        )\n","        ax.set_ylabel(\n","            axis_labels_from_ctype(\n","                sequence[i].coordinate_system[1], sequence[i].spatial_units[1]\n","            )\n","        )\n","\n","        # basic test:\n","        # expect the wcs of the plot_obj to follow the sequence\n","        # print(sequence[i].wcs == plot_obj.axes.wcs, sequence[0].wcs == sequence[i].wcs)\n","        return (plot_obj,)\n","\n","    anim = animation.FuncAnimation(\n","        fig, update_fig, init_func=None, frames=len(sequence), interval=60, repeat=True\n","    )\n","    plt.close(fig)\n","\n","    return anim"]},{"cell_type":"code","execution_count":null,"id":"dKTP__Uh30gz","metadata":{"id":"dKTP__Uh30gz"},"outputs":[],"source":["anim = animate_sequence(sq)\n","HTML(anim.to_jshtml())"]},{"cell_type":"markdown","id":"DV2bujqc30gz","metadata":{"id":"DV2bujqc30gz"},"source":["## 5. Reading and loading HMI data"]},{"cell_type":"markdown","id":"-e7JJPQT30gz","metadata":{"id":"-e7JJPQT30gz"},"source":["Now, we demonstrste how to read the HMI data within the SDOML dataset. In general, the HMI data structure is very similar to the AIA data. Instead of 9 AIA channels, for each time step, HMI has 3 channels that represent the 3 component of the vector magnetic field (i.e., Bx, By, and Bz). Using the same method described in section 2, we can load the HMI data in 2010:"]},{"cell_type":"code","execution_count":null,"id":"Os-PH8IY30gz","metadata":{"id":"Os-PH8IY30gz"},"outputs":[],"source":["root = load_single_aws_zarr(\n","    path_to_zarr=\"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2_hmi_small.zarr/\",\n",")\n","print(root.tree())"]},{"cell_type":"markdown","id":"lO_D6eA830gz","metadata":{"id":"lO_D6eA830gz"},"source":["Same as AIA data, the new HMI data also includes all fits header information with the same keywords. To find out the HMI keyword definition, one can refer to the following online document:\n","http://jsoc.stanford.edu/doc/keywords/JSOC_Keywords_for_metadata.pdf\n","\n","And one can list all the HMI keywords included:"]},{"cell_type":"code","execution_count":null,"id":"Ojs8qyJ_30gz","metadata":{"id":"Ojs8qyJ_30gz"},"outputs":[],"source":["data = root[\"2010\"][\"Bz\"]\n","sorted(data.attrs)"]},{"cell_type":"markdown","id":"54ezje7u30g0","metadata":{"id":"54ezje7u30g0"},"source":["Note that the HMI keywords are slightly different comparing with AIA keywords. For example, there is no exposure time ('EXPTIME') in the HMI metadata. Also, the 'T_OBS' format is a bit different:"]},{"cell_type":"code","execution_count":null,"id":"mv0LbDVD30g0","metadata":{"id":"mv0LbDVD30g0"},"outputs":[],"source":["t_obs = np.array(data.attrs[\"T_OBS\"])\n","t_obs"]},{"cell_type":"markdown","id":"s6CiVmSI30g0","metadata":{"id":"s6CiVmSI30g0"},"source":["To keep it consistent with the AIA metadata, one can simply convert the time format:"]},{"cell_type":"code","execution_count":null,"id":"k83WyMlq30g0","metadata":{"id":"k83WyMlq30g0"},"outputs":[],"source":["t_obs_new = []\n","for string in t_obs:\n","    new_string = string.replace('_TAI', 'Z')\n","    new_string = new_string.replace('_','T')\n","    new_string = new_string.replace('.','-')\n","    new_string = new_string.replace('Z', '.00')\n","    t_obs_new.append(new_string)\n","t = Time(t_obs_new, format='isot', scale='tai')\n","t_obs_new=t.value"]},{"cell_type":"markdown","id":"w4laL4fr30g0","metadata":{"id":"w4laL4fr30g0"},"source":["Now we can load a magnetic map using Sunpy Map:"]},{"cell_type":"code","execution_count":null,"id":"-TwHnObs5JQG","metadata":{"id":"-TwHnObs5JQG"},"outputs":[],"source":["da.from_array(data)[0, :, :]"]},{"cell_type":"code","execution_count":null,"id":"5pYhCnCf5gsZ","metadata":{"id":"5pYhCnCf5gsZ"},"outputs":[],"source":["selected_headr"]},{"cell_type":"code","execution_count":null,"id":"HdWQLzRa30g0","metadata":{"id":"HdWQLzRa30g0"},"outputs":[],"source":["selected_image = da.from_array(data)[0, :, :]\n","selected_headr = {keys: values[0] for keys, values in data.attrs.items()}\n","selected_headr['WAVEUNIT'] = 'angstrom'\n","my_map = sunpy.map.Map((np.array(selected_image), selected_headr))\n","my_map"]},{"cell_type":"markdown","id":"zwbmz9QV30g0","metadata":{"id":"zwbmz9QV30g0"},"source":["We can load a movie of HMI Bz component in the same time range as shown for AIA in the previous section:"]},{"cell_type":"code","execution_count":null,"id":"pOENhFnD30g0","metadata":{"id":"pOENhFnD30g0"},"outputs":[],"source":["df_time = pd.DataFrame(t_obs_new, index=np.arange(np.shape(t_obs_new)[0]), columns=[\"Time\"])\n","df_time[\"Time\"] = pd.to_datetime(df_time[\"Time\"])\n","\n","# select times at a frequency of 12 minutes\n","selected_times = pd.date_range(\n","    start=\"2010-08-28 00:00:00\", end=\"2010-08-28 23:59:59\", freq=\"12T\")\n","\n","selected_index = []\n","for i in selected_times:\n","    selected_index.append(np.argmin(abs(df_time[\"Time\"] - i)))\n","\n","#mark the missing timestamps in the data\n","missing_index=np.where(abs(df_time['Time'][selected_index]-selected_times)>pd.Timedelta('3m'))[0].tolist()\n","for i in missing_index:\n","    selected_index[i]=-1\n","\n","# may be a more efficient way of doing this\n","time_index = list(filter(lambda x: x > 0, selected_index))\n","da.from_array(data)[time_index, :, :]"]},{"cell_type":"code","execution_count":null,"id":"WbQwF3BE30g1","metadata":{"id":"WbQwF3BE30g1"},"outputs":[],"source":["maps = []\n","\n","for i in time_index:\n","    selected_image = da.from_array(data)[i, :, :]\n","    selected_headr = {keys: values[i] for keys, values in data.attrs.items()}\n","    selected_headr['WAVEUNIT'] = 'angstrom'\n","    maps.append(sunpy.map.Map((np.array(selected_image), selected_headr)))\n","\n","sq = sunpy.map.Map(maps, sequence=True, sortby=\"date\")"]},{"cell_type":"code","execution_count":null,"id":"WO2RwJ6v30g1","metadata":{"id":"WO2RwJ6v30g1","scrolled":true},"outputs":[],"source":["# The plot range can be specified by vmin and vmax\n","anim = animate_sequence(sq, vmin=-20, vmax=20)\n","HTML(anim.to_jshtml())"]},{"cell_type":"markdown","id":"8sdL0W7q30g1","metadata":{"id":"8sdL0W7q30g1"},"source":["## 6. Reading and loading EVE data"]},{"cell_type":"markdown","id":"0iL1hhfL30g1","metadata":{"id":"0iL1hhfL30g1"},"source":["The EVE data is timeseries data in 39 wavelengths from 2010 May 1 to 2014 May 26. The temporal resolution is 1 minute. In this section, we demonstrate how to read and load EVE data."]},{"cell_type":"code","execution_count":null,"id":"DVxBAlBN30g1","metadata":{"id":"DVxBAlBN30g1"},"outputs":[],"source":["root = load_single_aws_zarr(\n","    path_to_zarr=\"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2_eve.zarr/\",\n",")\n","print(root.tree())"]},{"cell_type":"markdown","id":"hfzyKr4S30g1","metadata":{"id":"hfzyKr4S30g1"},"source":["As shown in the data structure tree, the ion line names can be identified. For some ions, there are multiple emission lines and the spectral line names end with '_1', '_2' to distinguish them. The details (e.g., ion, wavelength, emission temperature) are included in the metadata, which can be checked similar as AIA and HMI data:"]},{"cell_type":"code","execution_count":null,"id":"xPuHTq0I30g1","metadata":{"id":"xPuHTq0I30g1"},"outputs":[],"source":["data = root[\"MEGS-A\"][\"Fe XX\"]\n","sorted(data.attrs)"]},{"cell_type":"code","execution_count":null,"id":"wmvhmxpS30g1","metadata":{"id":"wmvhmxpS30g1"},"outputs":[],"source":["data.attrs['ion'],data.attrs['wavelength'], data.attrs['logT']"]},{"cell_type":"markdown","id":"_nOklhER30g2","metadata":{"id":"_nOklhER30g2"},"source":["In addition, the 'Time' variable contains all timestamps of the data:"]},{"cell_type":"code","execution_count":null,"id":"Y-UxiMwZ30g2","metadata":{"id":"Y-UxiMwZ30g2"},"outputs":[],"source":["time = root['MEGS-A']['Time']\n","time[0:10]"]},{"cell_type":"markdown","id":"kwmVnHVI30g2","metadata":{"id":"kwmVnHVI30g2"},"source":["We can plot the spectral line timeseries data:"]},{"cell_type":"code","execution_count":null,"id":"u8sdGoA030g2","metadata":{"id":"u8sdGoA030g2"},"outputs":[],"source":["df = pd.Series(data,index=pd.to_datetime(time))\n","ax = df.plot(ylim=(0,2.e-4),figsize=(20,10),fontsize=20)\n","ax.set_title(str(data.attrs['ion'])+' '+str(data.attrs['wavelength'])+' LogT = '+str(data.attrs['logT']),fontsize=20)\n","ax.set_xlabel(\"Time\",fontsize=20)\n","ax.set_ylabel(\"Intensity [W/m^2]\",fontsize=20)"]},{"cell_type":"markdown","id":"HBSb6FFH30g2","metadata":{"id":"HBSb6FFH30g2"},"source":["----"]},{"cell_type":"markdown","id":"fMk-BmkT30g2","metadata":{"id":"fMk-BmkT30g2"},"source":["This project was conducted during the 2018 NASA Frontier Development Lab (FDL) program, a public/private partnership between NASA and SETI and industry partners including NVIDIA Corporation, Lockheed Martin, and IBM. The authors thank IBM (especially Naeem Altaf) for generously providing computing resources on the IBM Cloud."]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":5}
