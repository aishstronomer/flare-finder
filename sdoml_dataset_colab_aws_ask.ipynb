{"cells":[{"cell_type":"markdown","id":"399ed055","metadata":{},"source":["to-do\n","- create a dataset of images and tag them as is_big_flare - true or false\n","  - run the current notebook to get the hourly images for 2015 (no consideration for flare/no-flare)\n","  - make this code a module to get a function that can pull desired images from SDO-dataset\n","    - function schema: \n","      get_sdo_solar_images_from_aws(\n","          wanted_times, # list of datetimes for which images are desired\n","          save_folder_path, # folder path to save .png files\n","      ) -> fetched_image_paths # list of paths of image .png files saved\n","  - use the function to pull images pertaining to all big-flare events in 2015 and add to the images dataset\n","  - move on to making a flare classifier"]},{"cell_type":"code","execution_count":null,"id":"jaFbHF6Z30gq","metadata":{"executionInfo":{"elapsed":10626,"status":"ok","timestamp":1703180810715,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"jaFbHF6Z30gq"},"outputs":[],"source":["# %matplotlib inline\n","\n","import os\n","from typing import Union\n","import zarr\n","\n","# import gcsfs\n","import s3fs\n","import sunpy.map\n","\n","import dask.array as da\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import pandas as pd\n","import sunpy.visualization.colormaps as cm\n","\n","from astropy.time import Time\n","from dask.distributed import Client, LocalCluster\n","from sunpy.visualization import axis_labels_from_ctype, wcsaxes_compat\n","\n","from matplotlib import animation\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":null,"id":"c50f2c30","metadata":{},"outputs":[],"source":["# fix dask cache size\n","\n","from dask.cache import Cache\n","cache = Cache(1e9)  # Leverage 1 GB of memory\n","cache.register()    # Turn cache on globally"]},{"cell_type":"code","execution_count":null,"id":"XQGn2v6_30gr","metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1703180880946,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"XQGn2v6_30gr"},"outputs":[],"source":["# AWS_ZARR_ROOT = (\n","#     \"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2_small.zarr/\"\n","# )\n","\n","AWS_ZARR_ROOT = (\n","    \"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2.zarr/2015/\"\n",")\n","\n","def s3_connection(path_to_zarr: os.path) -> s3fs.S3Map:\n","    \"\"\"\n","    Instantiate connection to aws for a given path `path_to_zarr`\n","    \"\"\"\n","    return s3fs.S3Map(\n","        root=path_to_zarr,\n","        s3=s3fs.S3FileSystem(anon=True),\n","        # anonymous access requires no credentials\n","        check=False,\n","    )\n","\n","\n","def load_single_aws_zarr(\n","    path_to_zarr: os.path,\n","    cache_max_single_size: int = None,\n",") -> Union[zarr.Array, zarr.Group]:\n","    \"\"\"\n","    load zarr from s3 using LRU cache\n","    \"\"\"\n","    return zarr.open(\n","        zarr.LRUStoreCache(\n","            store=s3_connection(path_to_zarr),\n","            max_size=cache_max_single_size,\n","        ),\n","        mode=\"r\",\n","    )"]},{"cell_type":"markdown","id":"pHCnRpFi30gr","metadata":{"id":"pHCnRpFi30gr"},"source":["## 2. Reading and loading the AIA data\n"]},{"cell_type":"markdown","id":"u8yLRK4x30gr","metadata":{"id":"u8yLRK4x30gr"},"source":["The SDO ML dataset is stored in the Zarr format, a format for the storage of chunked, compressed, N-dimensional arrays with Numpy dtype. For an in-depth overview, see https://zarr.readthedocs.io/en/stable/tutorial.html."]},{"cell_type":"code","execution_count":null,"id":"IaWjptjK30gr","metadata":{"executionInfo":{"elapsed":1375,"status":"ok","timestamp":1703180885235,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"IaWjptjK30gr"},"outputs":[],"source":["# first, we create a group with the store data located on GCP.\n","root = load_single_aws_zarr(\n","    path_to_zarr=AWS_ZARR_ROOT,\n",")"]},{"cell_type":"code","execution_count":null,"id":"L5sUBFP-30gs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29107,"status":"ok","timestamp":1703180914336,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"L5sUBFP-30gs","outputId":"c7878077-e488-4284-93a3-b6569e74b7cc"},"outputs":[],"source":["# Using `root.tree()`, we are able to display the hierarchy (of `loc`).\n","# print(root.tree())"]},{"cell_type":"markdown","id":"4rkpT-1q30gs","metadata":{"id":"4rkpT-1q30gs"},"source":["As shown in the tree, the heirachy consists of groups, each shown with their respective shape, and data type. In this example, we will primarily look at the 171 Ã… channel from 2010. This consists of 6135 512x512 images, stored as float32, and can be accessed as follows:"]},{"cell_type":"code","execution_count":null,"id":"AEKhkUv330gt","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703180914336,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"AEKhkUv330gt"},"outputs":[],"source":["images_171a_zarray = root[\"171A\"]"]},{"cell_type":"markdown","id":"CP-3yVdt30gt","metadata":{"id":"CP-3yVdt30gt"},"source":["We could have alternatively accessed the 2010 data as:\n","\n","```\n","loc = 'fdl-sdoml-v2/sdomlv2_small.zarr/2010'\n","```\n","\n","which becomes increasingly useful in the full dataset (where the heirachy contains years 2010 - present)."]},{"cell_type":"markdown","id":"GOq4PfFF30gt","metadata":{"id":"GOq4PfFF30gt"},"source":["**Loading with Dask**\n","\n","We can then load this data into an array using dask."]},{"cell_type":"code","execution_count":null,"id":"uw-tZXju30gt","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1703180958378,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"uw-tZXju30gt","outputId":"f13b3d53-9363-43b0-8105-c6cc44ac701e"},"outputs":[],"source":["all_image = da.from_array(images_171a_zarray)\n","all_image"]},{"cell_type":"markdown","id":"39fny1di30gt","metadata":{"id":"39fny1di30gt"},"source":["As shown above, the data has the shape (6135, 512, 512), and is split into 52 chunks of (120, 512, 512), each of 125.83 MB; this is further visualised on the right. The data is now in a form to be manipulated like a Numpy array.\n","\n","We can load and display one image now:"]},{"cell_type":"code","execution_count":null,"id":"d8d03557","metadata":{},"outputs":[],"source":["image=all_image[0,:,:]\n","plt.figure(figsize=(5,5))\n","colormap = plt.get_cmap('sdoaia171')\n","plt.imshow(image.compute(),origin='lower',vmin=10,vmax=1000,cmap=colormap)"]},{"cell_type":"markdown","id":"nfMrsRiQ30gu","metadata":{"id":"nfMrsRiQ30gu"},"source":["Depending on the use-case, we may wish to extract a subset of this data in various ways. In the following sections we step through a number of potential operations that we may wish to make with the data."]},{"cell_type":"markdown","id":"9NCHr5-930gu","metadata":{"id":"9NCHr5-930gu"},"source":["### 2a. Selecting images based on header information"]},{"cell_type":"markdown","id":"gLRnFQv930gu","metadata":{"id":"gLRnFQv930gu"},"source":["The new data includes all fits header information with the same keywords. To find out the AIA keyword definition, one can refer to the following online document:\n","http://jsoc.stanford.edu/~jsoc/keywords/AIA/AIA02840_K_AIA-SDO_FITS_Keyword_Document.pdf\n","\n","And one can list all the AIA keywords included:"]},{"cell_type":"markdown","id":"pCxxPVNz30gu","metadata":{"id":"pCxxPVNz30gu"},"source":["We can extract the exposure (and observation) time from the data attributes (the header information), and downsample our data based upon that information."]},{"cell_type":"markdown","id":"p8nxNvye30gv","metadata":{"id":"p8nxNvye30gv"},"source":["### 2b. Selecting images based on indices"]},{"cell_type":"markdown","id":"Xf5x4ocU30gv","metadata":{"id":"Xf5x4ocU30gv"},"source":["While the data is not currently ordered by observation time, we can simple index the array to extract a number of observations"]},{"cell_type":"code","execution_count":null,"id":"6kOskhiHaIgF","metadata":{"executionInfo":{"elapsed":184,"status":"ok","timestamp":1703181025489,"user":{"displayName":"Aishwarya Kumar","userId":"02408787263645623141"},"user_tz":300},"id":"6kOskhiHaIgF"},"outputs":[],"source":["# We are going to choose data in 1 hour intervals\n","\n","\n","# df_time = pd.DataFrame(t_obs, index=np.arange(np.shape(t_obs)[0]), columns=[\"Time\"])\n","# df_time[\"Time\"] = pd.to_datetime(df_time[\"Time\"])\n","\n","# select times at a frequency of 60 minutes\n","wanted_times = pd.date_range(\n","    start=\"2015-01-01 00:00:00\", end=\"2015-12-31 23:59:59\", freq=\"60T\", tz=\"UTC\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"90dac6ed","metadata":{},"outputs":[],"source":["# [NEW] select subset of images based on time\n","\n","# get the indices of the images that are closest to the wanted times: images_zry_wanted_idxs\n","images_zry_wanted_idxs = []\n","images_zry_times = pd.to_datetime(np.array(images_171a_zarray.attrs[\"T_OBS\"]))\n","for selected_time in wanted_times[None:None]:\n","    images_zry_wanted_idxs.append(np.argmin(abs(images_zry_times - selected_time)))\n","images_zry_wanted_idxs = sorted(set(images_zry_wanted_idxs))\n","\n","# get wanted times\n","images_wanted_times = images_zry_times[images_zry_wanted_idxs]\n","\n","print(\"images_zry_wanted_idxs = \", images_zry_wanted_idxs)\n","print(\"len(images_zry_wanted_idxs) = \", len(images_zry_wanted_idxs))"]},{"cell_type":"code","execution_count":null,"id":"36d591b5","metadata":{},"outputs":[],"source":["# get one image from aws\n","\n","\n","def get_single_solar_image(image_idx, images_171a_zarray=images_171a_zarray):\n","    images_wanted_drry = da.from_array(images_171a_zarray)\n","    image = np.array(images_wanted_drry[image_idx, :, :])\n","    return image\n","\n","\n","image = get_single_solar_image(images_zry_wanted_idxs[4002])\n","\n","# downsample the image to 256 by sampling every other pixel\n","downsampled_pxl_posns = np.arange(0, image.shape[0], 2)\n","image_downsmpd = image[downsampled_pxl_posns, :][:, downsampled_pxl_posns]\n","\n","plt.figure(figsize=(5, 5))\n","plt.imshow(image, origin=\"lower\", vmin=10, vmax=1000, cmap=plt.get_cmap(\"sdoaia171\"))\n","plt.figure(figsize=(5, 5))\n","plt.imshow(\n","    image_downsmpd, origin=\"lower\", vmin=10, vmax=1000, cmap=plt.get_cmap(\"sdoaia171\")\n",")"]},{"cell_type":"code","execution_count":null,"id":"7ab3ed97","metadata":{},"outputs":[],"source":["# ASH is TESTINg.....\n","\n","# TODO: change the code to track images_processed_times and don't use images_df\n","#       - also stop using csvs\n","#       - save each image as a PNG and name it with the datetime in format\n","#         dt=yyyy-mm-dd_hhmmss.png e.g. dt=2015-01-01_170400.png\n","\n","import pandas as pd\n","import glob\n","import os\n","import re\n","import sys\n","\n","# get the images that have been processed already: images_processed_times\n","images_png_folder = \"/Users/aishsk6/gd_to_be_archived_big_files/sdo_image_data\"\n","images_processed_paths = glob.glob(os.path.join(images_png_folder, \"*.png\"))\n","images_processed_times = [\n","    pd.to_datetime(re.sub(\".png\", \"\", os.path.basename(path)))\n","    for path in images_processed_paths\n","]\n","\n","for image_time in images_wanted_times[None:None]:\n","    current_img_time = image_time\n","    # print(f\"current_img_time: {current_img_time}\")\n","\n","    # get the position of image_time in images_wanted_times\n","    image_time_idx = list(images_wanted_times).index(image_time)\n","    # print(f\"image_time_idx: {image_time_idx}\")\n","\n","    # check if the images_processed_times contains the row currently being processed and skip iter if true\n","    if current_img_time in images_processed_times:\n","        # print('current_img_time:', current_img_time, 'images_processed_times:', images_processed_times)\n","        print(\n","            f\"Skipping image_time_idx {image_time_idx} as it has been processed already.\"\n","        )\n","        continue\n","\n","    # get current image\n","    image_arr = get_single_solar_image(images_zry_wanted_idxs[image_time_idx])[\n","        downsampled_pxl_posns, :\n","    ][:, downsampled_pxl_posns]\n","    print(sys.getsizeof(image_arr) / (1024 * 1024))\n","\n","\n","    # # Processing image\n","    # fig = plt.figure(figsize=(5, 5))\n","    # plt.imshow(image_arr, origin=\"lower\", vmin=10, vmax=1000, cmap=\"sdoaia171\")\n","    # plt.savefig(f\"{images_png_folder}/{current_img_time}.png\")\n","    # plt.close(\"all\")  # Close the figure manually to release resources\n","\n","    # # Explicit memory management\n","    # del image_arr\n","    # gc.collect()\n","\n","    print(f\"image_time_idx: {image_time_idx} of {len(images_wanted_times)}\")"]},{"cell_type":"code","execution_count":null,"id":"d3fc6a74","metadata":{},"outputs":[],"source":["import sys\n","\n","sys.getsizeof(images_zry_times) / (1024 ** 2)"]},{"cell_type":"code","execution_count":null,"id":"b8a2a665","metadata":{},"outputs":[],"source":["images_processed_times"]},{"cell_type":"code","execution_count":null,"id":"0bc43220","metadata":{},"outputs":[],"source":["current_img_time"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":5}
